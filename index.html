<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Academic Project Page</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>

  <nav class="navbar" role="navigation" aria-label="main navigation">
    <div class="navbar-brand">
      <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
        <span aria-hidden="true"></span>
      </a>
    </div>
    <div class="navbar-menu">
      <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
        <div class="navbar-item has-dropdown is-hoverable">
          <a class="navbar-link">
            More Research
          </a>
          <div class="navbar-dropdown">
            <a class="navbar-item" href="https://github.com/OpenGVLab/SAM-Med2D/">
              SAM-Med2D
            </a>
            <a class="navbar-item" href="https://github.com/uni-medical/SAM-Med3D/">
              SAM-Med3D 
              <a class="navbar-item" href="https://github.com/OpenGVLab/Multi-Modality-Arena/">
                OmniMedVQA
              </a>
            </a>
            
            </a>
          </div>
        </div>
      </div>
  
    </div>
  </nav>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              <img src="static/images/mmbench_icon.jpg" style="width:1em;vertical-align: middle" alt="Logo"/> 
              <span class="mmmu" style="vertical-align: middle">GMAI-MMBench</span>
              </h1>
            <h2 class="subtitle is-3 publication-subtitle">
              A Comprehensive Multimodal
              Evaluation Benchmark Towards General Medical AI
              <!-- <br> -->
            </h2>
            </h1>
              <div class="is-size-5 publication-authors">
                <span class="author-block">Pengcheng Chen*<sup style="color:#ffac33;">1,2</sup>,</span>
                <span class="author-block">Jin Ye*<sup style="color:#ed4b82;">1,3</sup>,</span>
                <span class="author-block">Guoan Wang*<sup style="color:#007bff;">1,4</sup>,</span>
                <span class="author-block">Yanjun Li<sup style="color:#007bff;">1,4</sup>,</span><br>
                <span class="author-block">Zhongying Deng<sup style="color:#ffac33;">5</sup>,</span>
                <span class="author-block">Wei Li<sup style="color:#ed4b82;">1,6</sup>,</span>
                <span class="author-block">Tianbin Li<sup style="color:#ed4b82;">1</sup>,</span>
                <span class="author-block">Haodong Duan<sup style="color:#ffac33;">1</sup>,</span>
                <span class="author-block">Ziyan Huang<sup style="color:#ffac33;">1,6</sup>,</span>
                <span class="author-block">Yanzhou Su<sup style="color:#6fbf73;">1</sup>,</span>
                <span class="author-block">Benyou Wang<sup style="color:#9b51e0;">7,8</sup>,</span>
                <span class="author-block">Shaoting Zhang<sup style="color:#6fbf73;">1</sup>,</span>
                <span class="author-block">Bin Fu<sup style="color:#60121572;">9</sup>,</span>
                <span class="author-block">Jianfei Cai<sup style="color:#ed4b82;">3</sup>,</span>
                <span class="author-block">Bohan Zhuang<sup style="color:#ed4b82;">3</sup>,</span>
                <span class="author-block">Eric J Seibel<sup style="color:#ffac33;">2</sup>,</span>
                <span class="author-block">Junjun He<sup style="color:#6fbf73;">†,1</sup>,</span>
                <span class="author-block">Yu Qiao<sup style="color:#6fbf73;">†,1</sup>,</span>
              </div>
          
              <br>
          
              <div class="is-size-5 publication-authors">
                <span class="author-block"><sup style="color:#6fbf73;">1</sup>Shanghai AI Laboratory,</span>
                <span class="author-block"><sup style="color:#ffac33;">2</sup>University of Washington,</span>
                <span class="author-block"><sup style="color:#ed4b82;">3</sup>Monash University,</span>
                <span class="author-block"><sup style="color:#007bff;">4</sup>East China Normal University,</span></br>
                <span class="author-block"><sup style="color:#ffac33;">5</sup>University of Cambridge,</span>
                <span class="author-block"><sup style="color:#ed4b82;">6</sup>Shanghai Jiao Tong University,</span>
                <span class="author-block"><sup style="color:#9b51e0;">7</sup>The Chinese University of Hong Kong, Shenzhen</span>
                <span class="author-block"><sup style="color:#ff00f2;">8</sup>Shenzhen Research Institute of Big Data</span>
                <span class="author-block"><sup style="color:#60121572;">9</sup>Shenzhen Institute of Advanced Technology (SIAT), Chinese Academy of Sciences</span>
              </div>
    
              <br>
              <div class="is-size-5 publication-authors">
                <span class="author-block">*Core Contributors</span><br>
                <span class="author-block">†Corresponding to:</span>
                <span class="author-block"><a href="mailto:xiangyue.work@gmail.com">hejunjun@pjlab.org.cn</a>,</span>
                <span class="author-block"><a href="mailto:su.809@osu.edu">qiaoyu@pjlab.org.cn</a>,</span>
              </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/<ARXIV PAPER ID>.pdf" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/YOUR REPO HERE" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<section class="hero teaser">
  <div class="container is-max-desktop">
        <div class="content has-text-centered">
          <img src="static/images/cover.jpg" alt="geometric reasoning" width="100%"/>
          <p>  Overview of the GMAI-MMbench. GMAI-MMbench focuses on medical image understanding and reasoning in real-world clinical scenarios with three key features: (1) Comprehensive medical knowledge: It consists of 285 diverse clinical-related datasets from worldwide sources, covering 38 modalities. (2) Well-organized data structure: It features 19 clinical VQA tasks across 18 clinical departments, meticulously categorized into a lexical tree. (3) Multi-perceptual granularity: Interactive methods span from image to region level, offering varying degrees of perceptual details.
          </div>
    </div>
  </div>
</section>

<section class="section">
  <div class="container" style="margin-bottom: 2vh;">
    <!-- Abstract. -->
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">🔔News</h2>
        <div class="content has-text-justified">
          <p>
            <b>🚀[2024-06-05]: Submit on nips2024!🌟</b>
          </p>
      </div>      
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Large Vision-Language Models (LVLMs) are capable of handling diverse data types such as imaging, text, and physiological signals, and can be applied in various fields. In the medical field, LVLMs have a high potential to offer substantial assistance for diagnosis and treatment. Before that, it is crucial to develop benchmarks to evaluate LVLMs' effectiveness in various medical applications. Current benchmarks are often built upon academic literature, mainly focusing on a single domain, and lacking varying perceptual granularities. Thus, they face specific challenges, including limited clinical relevance, incomplete evaluations, and insufficient guidance for interactive LVLMs. To address these limitations, we developed GMAI-MMbench, the most comprehensive and fine-grained GMAI benchmark to date. It is constructed from 285 datasets across 38 medical image modalities, 19 clinical-related tasks, and 18 departments in a Visual Question Answering (VQA) format. Additionally, we implemented a lexical tree structure that allows users to customize evaluation tasks, accommodating various assessment needs and substantially supporting medical AI research and applications. We evaluated 50 LVLMs, and the results show that even the advanced GPT-4o only achieves an accuracy of 52\%, indicating significant room for improvement. Moreover, we identified 5 main insufficiencies to be addressed in the next-generation LVLMs. Addressing them can advance the development of cutting-edge LVLMs for medical applications. We believe GMAI-MMbench will stimulate the community to build the next generation of LVLMs toward GMAI.
          </p>
        </div>
      </div>
    </div>
    <!--/ Abstract. -->
</div>
</section>

<!-- DATASET SECTION -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
  <h1 class="title is-1 mmmu">
    <img src="static/images/mmbench_icon.jpg" style="width:1em;vertical-align: middle" alt="Logo"/>
    <span class="mmmu" style="vertical-align: middle">GMAI-MMBench</span>
  </h1>
  </div>
</section>

<section class="section">
  <div class="container">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Overview</h2>
        <div class="content has-text-justified">
          <p>
            We propose GMAI-MMbench, an innovative benchmark meticulously designed for the medical field, capable of providing comprehensive evaluations of LVLMs across various aspects of healthcare. Our team collected 285 datasets from public sources and hospitals over one year, covering medical imaging tasks of detection, classification, and segmentation, to form the data fuel for establishing such a benchmark. The detailed datasets are listed in the supplementary. Based on the data foundation, we design a reliable pipeline to generate question-answering pairs and organize them across different aspects with manual validation. Finally, we carefully select approximately 26K questions with varying levels of perceptual granularity from the filtered cases to construct the final GMAI-MMbench.</p>
          <img src="static/images/workflow.png" alt="algebraic reasoning" class="center">
          <br>
          <p>
            Overall illustration of GMAI-MMbench. It can be divided into three core steps: 1) Data curation and preprocessing: We standardize both images and labels after curating 285 datasets. 2) Label categorization and lexical tree construction: We categorize all labels into 19 clinical VQA tasks and 18 clinical departments, then export a lexical tree for easily customized evaluation. 3) QA generation and selection: During the generation process, each question must include information about image modality and corresponding annotation granularity. The final benchmark is obtained through additional expert validation and manual selection.
          </p>
        </div>
    </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Lexical Tree</h2>
        <div class="content has-text-justified">
          <p>
            In this work, to make the GMAI-MMBench more intuitive and user-friendly, we have systematized our labels and structured the entire dataset into a lexical tree. Users can freely select the test contents based on this lexical tree. We believe that this customizable benchmark will effectively guide the improvement of models in specific areas.
        </p>
        <div class="content has-text-centered">
          <img src="static/images/tree.png" alt="algebraic reasoning" class="center">
          <p> Sampled MMMU examples from each discipline. The questions and images need expert-level knowledge to understand and reason.</p>
        </div>
        </div>
    </div>
    </div>


    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Comparisons with Existing Benchmarks</h2>
        <div class="content has-text-justified">
          <p>
            To further distinguish the difference between <i>dataset</i> and other existing ones, we elaborate the benchmark details in Figure. 
            From the <i>breadth</i> perspective, the prior benchmarks are heavily focused on daily knowledge and common sense. 
            The covered image format is also limited. Our benchmark aims to cover college-level knowledge with 30 image formats including diagrams, 
            tables, charts, chemical structures, photos, paintings, geometric shapes, music sheets, medical images, etc. 
            In the <i>depth</i> aspect, the previous benchmarks normally require commonsense knowledge or simple physical or temporal reasoning. 
            In contrast, our benchmark requires deliberate reasoning with college-level subject knowledge.
        </p>
        <div class="content has-text-centered">
          <img src="static/images/compare.Jpeg" alt="algebraic reasoning" class="center">
          <p> Sampled MMMU examples from each discipline. The questions and images need expert-level knowledge to understand and reason.</p>
        </div>
        </div>
    </div>
    </div>

    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3">Statistics</h2>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/mmmu_subject_distribution.Jpeg" alt="algebraic reasoning" width="95%"/>
              <p> Sampled MMMU examples from each discipline. The questions and images need expert-level knowledge to understand and reason.</p>
            </div>
          </div>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/statistics.png" alt="arithmetic reasoning" width="40%"/>
              <p> Key statistics of the MMMU benchmark</p>
            </div>
          </div>
          <div class="box m-5">
            <div class="content has-text-centered">
              <img src="static/images/image_type_count.png" alt="arithmetic reasoning" width="80%"/>
              <p> Distribution of image types in the MMMU dataset</p>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- RESULTS SECTION -->
<section class="hero is-light is-small">
  <div class="hero-body has-text-centered">
    <!-- <img src="static/images/mmbench_icon.jpg" style="width:1em;vertical-align: middle" alt="Logo"/> -->
    <h1 class="title is-1 mmmu">Experiment Results</h1>
  </div>
</section>
<section class="section">
  <div class="container">



<!-------------------------------------------------------------------- RESULTS SECTION -------------------------------------------------------------------->
    <div class="columns is-centered m-6">
      <div class="column is-full has-text-centered content">
        <h2 class="title is-3" id="leaderboard">Leaderboard</h2>
        <div class="content">
          <div class="content has-text-justified">
            <p>
              We evaluate various models including LLMs and LMMs.
              In each type, we consider both closed- and open-source models.
              Our evaluation is conducted under a zero-shot setting to assess the capability of models to generate accurate answers without fine-tuning or few-shot demonstrations on our benchmark.
              For all models, we use the default prompt provided by each model for multi-choice or open QA, if available.
              If models do not provide prompts for task types in MMMU, we conduct prompt engineering on the validation set and use the most effective prompt for the later zero-shot experiment.

            </p>
          </div>

          <button id="toggleButton" onclick="changeButtonText()"><b style='font-size: larger;'>Clinical VQA Tasks Results</b> (Click to Switch)</button>
          <!-- <div class="model-labels-container">
            <span class="leaderboard-label" style="background-color: rgba(255, 208, 80, 0.15);">Human Expert</span>
            <span class="leaderboard-label" style="background-color: rgba(249, 242, 248, 1);">Open-Source</span>
            <span class="leaderboard-label" style="background-color: rgba(117, 209, 215, 0.1);">Proprietary</span>
          </div> -->
          <!-- Validation Set Leaderboard -->
          <table id="table1" class="js-sort-table">
            <tr>
              <td class="js-sort-string"><strong>Model name</strong></td>
              <td class="js-sort-string"><strong>Size</strong></td>
              <td class="js-sort-number"><strong>Overall (val)</strong></td>
              <td class="js-sort-number"><strong>Overall (test)</strong></td>
              <td class="js-sort-number"><strong>AR</strong></td>
              <td class="js-sort-number"><strong>BVR</strong></td>
              <td class="js-sort-number"><strong>B</strong></td>
              <td class="js-sort-number"><strong>CR</strong></td>
              <td class="js-sort-number"><strong>C</strong></td>
              <td class="js-sort-number"><strong>DD</strong></td>
              <td class="js-sort-number"><strong>IQG</strong></td>
              <td class="js-sort-number"><strong>MR</strong></td>
              <td class="js-sort-number"><strong>M</strong></td>
              <td class="js-sort-number"><strong>NT</strong></td>
              <td class="js-sort-number"><strong>OR-A</strong></td>
              <td class="js-sort-number"><strong>OR-HN</strong></td>
              <td class="js-sort-number"><strong>OR-P</strong></td>
              <td class="js-sort-number"><strong>OR-T</strong></td>
              <td class="js-sort-number"><strong>SG</strong></td>
              <td class="js-sort-number"><strong>SAR</strong></td>
              <td class="js-sort-number"><strong>SIR</strong></td>
              <td class="js-sort-number"><strong>SWR</strong></td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
              <td>Random</td>
              <td>-</td>
              <td>25.04</td>
              <td>26.17</td>
              <td>37.59</td>
              <td>25.85</td>
              <td>23.37</td>
              <td>22.32</td>
              <td>25.56</td>
              <td>26.37</td>
              <td>26.42</td>
              <td>28.16</td>
              <td>20.80</td>
              <td>26.50</td>
              <td>22.68</td>
              <td>23.03</td>
              <td>23.47</td>
              <td>21.76</td>
              <td>31.46</td>
              <td>25.19</td>
              <td>21.63</td>
              <td>25.71</td>
            </tr>
            <tr>
              <td colspan="22" style="text-align: center;">Medical Special Model</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
              <td>MedVInT</td>
              <td>-</td>
              <td>2.10</td>
              <td>1.92</td>
              <td>5.27</td>
              <td>0.00</td>
              <td>0.39</td>
              <td>0.00</td>
              <td>1.95</td>
              <td>1.94</td>
              <td>4.47</td>
              <td>0.00</td>
              <td>0.00</td>
              <td>0.00</td>
              <td>0.25</td>
              <td>0.00</td>
              <td>0.00</td>
              <td>0.19</td>
              <td>7.84</td>
              <td>0.00</td>
              <td>1.97</td>
              <td>0.00</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
              <td>Med-Flamingo</td>
              <td>8.3B</td>
              <td>10.94</td>
              <td>12.02</td>
              <td>8.43</td>
              <td>8.30</td>
              <td>10.05</td>
              <td>11.44</td>
              <td>7.07</td>
              <td>13.95</td>
              <td>12.60</td>
              <td>6.48</td>
              <td>7.20</td>
              <td>18.50</td>
              <td>8.43</td>
              <td>20.17</td>
              <td>15.96</td>
              <td>9.16</td>
              <td>13.79</td>
              <td>5.00</td>
              <td>8.94</td>
              <td>10.57</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
              <td>LLaVA-Med</td>
              <td>-</td>
              <td>18.78</td>
              <td>20.20</td>
              <td>25.64</td>
              <td>18.49</td>
              <td>20.89</td>
              <td>21.22</td>
              <td>16.24</td>
              <td>20.47</td>
              <td>21.95</td>
              <td>18.98</td>
              <td>15.20</td>
              <td>16.50</td>
              <td>20.57</td>
              <td>27.23</td>
              <td>18.31</td>
              <td>17.56</td>
              <td>20.56</td>
              <td>20.77</td>
              <td>15.19</td>
              <td>20.00</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
              <td>Qilin-Med-VL-Chat</td>
              <td>-</td>
              <td>21.29</td>
              <td>22.35</td>
              <td>30.68</td>
              <td>21.13</td>
              <td>17.36</td>
              <td>21.96</td>
              <td>15.49</td>
              <td>24.01</td>
              <td>17.48</td>
              <td>17.47</td>
              <td>10.00</td>
              <td>16.00</td>
              <td>26.27</td>
              <td>17.14</td>
              <td>11.27</td>
              <td>15.65</td>
              <td>26.01</td>
              <td>25.58</td>
              <td>16.71</td>
              <td>27.14</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
              <td>RadFM</td>
              <td>14B</td>
              <td>22.60</td>
              <td>23.06</td>
              <td>27.87</td>
              <td>21.70</td>
              <td>14.75</td>
              <td>18.63</td>
              <td>21.20</td>
              <td>24.64</td>
              <td>22.76</td>
              <td>22.59</td>
              <td>16.40</td>
              <td>12.50</td>
              <td>19.21</td>
              <td>24.87</td>
              <td>8.92</td>
              <td>16.22</td>
              <td>30.39</td>
              <td>18.85</td>
              <td>19.21</td>
              <td>30.29</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
              <td>MedDr</td>
              <td>40B</td>
              <td>43.41</td>
              <td>43.12</td>
              <td>41.22</td>
              <td>48.30</td>
              <td>34.73</td>
              <td>29.52</td>
              <td>27.82</td>
              <td>52.29</td>
              <td>33.74</td>
              <td>31.33</td>
              <td>30.80</td>
              <td>49.50</td>
              <td>35.32</td>
              <td>49.75</td>
              <td>22.54</td>
              <td>47.71</td>
              <td>33.61</td>
              <td>25.58</td>
              <td>25.02</td>
              <td>31.14</td>
            </tr>
            <tr>
              <td colspan="22" style="text-align: center;">Open-Source VLMs</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>CogVLM-grounding-generalist</td>
              <td>17B</td>
              <td>5.09</td>
              <td>5.52</td>
              <td>3.75</td>
              <td>3.96</td>
              <td>1.44</td>
              <td>2.40</td>
              <td>10.53</td>
              <td>7.86</td>
              <td>8.94</td>
              <td>0.30</td>
              <td>0.00</td>
              <td>10.50</td>
              <td>8.67</td>
              <td>1.51</td>
              <td>0.47</td>
              <td>0.95</td>
              <td>1.73</td>
              <td>0.19</td>
              <td>3.57</td>
              <td>0.57</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>XComposer</td>
              <td>8B</td>
              <td>7.43</td>
              <td>7.80</td>
              <td>1.41</td>
              <td>6.60</td>
              <td>7.31</td>
              <td>13.28</td>
              <td>23.76</td>
              <td>7.53</td>
              <td>6.50</td>
              <td>6.02</td>
              <td>3.60</td>
              <td>14.50</td>
              <td>3.84</td>
              <td>10.42</td>
              <td>0.94</td>
              <td>11.64</td>
              <td>11.64</td>
              <td>6.92</td>
              <td>3.04</td>
              <td>4.00</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>PandaGPT 13B</td>
              <td>13B</td>
              <td>17.90</td>
              <td>15.35</td>
              <td>24.94</td>
              <td>16.23</td>
              <td>14.36</td>
              <td>23.43</td>
              <td>15.49</td>
              <td>14.80</td>
              <td>13.82</td>
              <td>12.20</td>
              <td>23.20</td>
              <td>28.50</td>
              <td>15.61</td>
              <td>25.55</td>
              <td>6.57</td>
              <td>14.89</td>
              <td>11.15</td>
              <td>10.38</td>
              <td>12.33</td>
              <td>8.29</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>Flamingo v2</td>
              <td>9B</td>
              <td>25.61</td>
              <td>26.44</td>
              <td>34.89</td>
              <td>24.15</td>
              <td>21.80</td>
              <td>21.77</td>
              <td>21.80</td>
              <td>28.18</td>
              <td>23.98</td>
              <td>25.00</td>
              <td>16.80</td>
              <td>32.50</td>
              <td>26.02</td>
              <td>22.52</td>
              <td>19.72</td>
              <td>21.56</td>
              <td>32.70</td>
              <td>21.54</td>
              <td>18.95</td>
              <td>26.29</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>VisualGLM-6B</td>
              <td>7.8B</td>
              <td>29.34</td>
              <td>30.48</td>
              <td>37.35</td>
              <td>30.38</td>
              <td>25.33</td>
              <td>27.31</td>
              <td>24.51</td>
              <td>33.51</td>
              <td>28.86</td>
              <td>27.41</td>
              <td>21.60</td>
              <td>38.00</td>
              <td>31.47</td>
              <td>26.05</td>
              <td>26.29</td>
              <td>29.77</td>
              <td>29.89</td>
              <td>20.58</td>
              <td>17.34</td>
              <td>38.57</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>Idefics-9B-Instruct</td>
              <td>9B</td>
              <td>29.63</td>
              <td>31.18</td>
              <td>40.75</td>
              <td>25.28</td>
              <td>27.02</td>
              <td>32.47</td>
              <td>22.26</td>
              <td>34.89</td>
              <td>23.98</td>
              <td>26.51</td>
              <td>24.40</td>
              <td>26.50</td>
              <td>24.16</td>
              <td>30.59</td>
              <td>38.97</td>
              <td>23.09</td>
              <td>30.55</td>
              <td>25.19</td>
              <td>21.72</td>
              <td>30.86</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>InstructBLIP-7B</td>
              <td>8B</td>
              <td>30.25</td>
              <td>31.20</td>
              <td>43.68</td>
              <td>27.92</td>
              <td>23.50</td>
              <td>28.97</td>
              <td>22.56</td>
              <td>35.45</td>
              <td>30.08</td>
              <td>30.12</td>
              <td>26.80</td>
              <td>31.00</td>
              <td>25.03</td>
              <td>30.25</td>
              <td>21.13</td>
              <td>23.28</td>
              <td>30.06</td>
              <td>20.38</td>
              <td>20.38</td>
              <td>25.43</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>Mini-Gemini-7B</td>
              <td>7B</td>
              <td>31.55</td>
              <td>31.17</td><td>32.44</td>
              <td>34.34</td>
              <td>27.02</td>
              <td>30.07</td>
              <td>9.77</td>
              <td>35.86</td>
              <td>29.27</td>
              <td>29.07</td>
              <td>23.60</td>
              <td>37.00</td>
              <td>32.09</td>
              <td>39.33</td>
              <td>22.07</td>
              <td>30.53</td>
              <td>20.56</td>
              <td>25.58</td>
              <td>20.02</td>
              <td>30.29</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>MMAlaya</td>
              <td>7.8B</td>
              <td>32.81</td>
              <td>31.86</td>
              <td>43.56</td>
              <td>40.57</td>
              <td>29.77</td>
              <td>33.95</td>
              <td>27.97</td>
              <td>34.71</td>
              <td>26.02</td>
              <td>31.48</td>
              <td>22.00</td>
              <td>49.50</td>
              <td>15.86</td>
              <td>29.58</td>
              <td>8.92</td>
              <td>32.63</td>
              <td>29.98</td>
              <td>23.08</td>
              <td>22.52</td>
              <td>28.86</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>Yi-VL-6B</td>
              <td>6.6B</td>
              <td>33.27</td>
              <td>34.33</td>
              <td>41.80</td>
              <td>33.21</td>
              <td>25.59</td>
              <td>30.07</td>
              <td>32.78</td>
              <td>38.42</td>
              <td>26.02</td>
              <td>25.45</td>
              <td>26.00</td>
              <td>36.00</td>
              <td>28.50</td>
              <td>34.79</td>
              <td>46.01</td>
              <td>22.71</td>
              <td>34.43</td>
              <td>24.42</td>
              <td>25.92</td>
              <td>30.86</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>LLaVA-NeXT-vicuna-7B</td>
              <td>7.1B</td>
              <td>34.59</td>
              <td>35.25</td>
              <td>41.33</td>
              <td>36.97</td>
              <td>20.76</td>
              <td>35.79</td>
              <td>23.31</td>
              <td>41.69</td>
              <td>36.59</td>
              <td>30.42</td>
              <td>24.27</td>
              <td>48.00</td>
              <td>23.08</td>
              <td>36.53</td>
              <td>14.89</td>
              <td>25.82</td>
              <td>31.87</td>
              <td>25.00</td>
              <td>24.22</td>
              <td>31.43</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>CogVLM-Chat</td>
              <td>17B</td>
              <td>35.46</td>
              <td>35.97</td>
              <td>41.69</td>
              <td>34.91</td>
              <td>26.76</td>
              <td>33.39</td>
              <td>20.00</td>
              <td>41.39</td>
              <td>36.18</td>
              <td>34.04</td>
              <td>21.60</td>
              <td>40.00</td>
              <td>33.09</td>
              <td>39.66</td>
              <td>23.94</td>
              <td>32.63</td>
              <td>35.76</td>
              <td>21.54</td>
              <td>21.89</td>
              <td>27.14</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>Qwen-VL</td>
              <td>9.6B</td>
              <td>35.58</td>
              <td>35.58</td>
              <td>37.94</td>
              <td>34.34</td>
              <td>31.07</td>
              <td>27.31</td>
              <td>24.96</td>
              <td>43.05</td>
              <td>23.17</td>
              <td>28.01</td>
              <td>20.40</td>
              <td>47.00</td>
              <td>30.61</td>
              <td>32.10</td>
              <td>30.52</td>
              <td>26.72</td>
              <td>30.88</td>
              <td>22.50</td>
              <td>19.57</td>
              <td>26.57</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>mPLUG-Owl2</td>
              <td>8.2B</td>
              <td>36.07</td>
              <td>35.86</td>
              <td>40.05</td>
              <td>38.87</td>
              <td>30.68</td>
              <td>37.64</td>
              <td>27.07</td>
              <td>41.99</td>
              <td>30.89</td>
              <td>31.63</td>
              <td>26.40</td>
              <td>42.50</td>
              <td>19.33</td>
              <td>40.50</td>
              <td>15.02</td>
              <td>29.58</td>
              <td>31.30</td>
              <td>21.92</td>
              <td>22.97</td>
              <td>30.00</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>Monkey</td>
              <td>9.8B</td>
              <td>36.24</td>
              <td>35.85</td>
              <td>39.46</td>
              <td>37.36</td>
              <td>32.25</td>
              <td>33.39</td>
              <td>22.26</td>
              <td>42.95</td>
              <td>28.86</td>
              <td>28.61</td>
              <td>19.20</td>
              <td>35.00</td>
              <td>27.39</td>
              <td>32.27</td>
              <td>31.46</td>
              <td>28.82</td>
              <td>32.54</td>
              <td>21.15</td>
              <td>20.20</td>
              <td>29.14</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>ShareCaptioner</td>
              <td>8B</td>
              <td>36.34</td>
              <td>35.96</td>
              <td>42.39</td>
              <td>32.83</td>
              <td>31.72</td>
              <td>28.23</td>
              <td>30.23</td>
              <td>41.28</td>
              <td>27.24</td>
              <td>32.83</td>
              <td>28.80</td>
              <td>43.50</td>
              <td>25.28</td>
              <td>36.30</td>
              <td>28.64</td>
              <td>37.21</td>
              <td>29.89</td>
              <td>20.38</td>
              <td>27.70</td>
              <td>27.71</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>Qwen-VL-Chat</td>
              <td>9.6B</td>
              <td>36.63</td>
              <td>36.32</td>
              <td>39.70</td>
              <td>39.25</td>
              <td>33.29</td>
              <td>29.89</td>
              <td>26.92</td>
              <td>43.43</td>
              <td>25.61</td>
              <td>28.92</td>
              <td>28.40</td>
              <td>43.50</td>
              <td>28.13</td>
              <td>31.93</td>
              <td>25.35</td>
              <td>24.24</td>
              <td>33.77</td>
              <td>18.46</td>
              <td>20.11</td>
              <td>32.86</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>LLaVA-NeXT-mistral-7B</td>
              <td>7.6B</td>
              <td>36.71</td>
              <td>37.06</td>
              <td>39.70</td>
              <td>30.03</td>
              <td>22.45</td>
              <td>29.52</td>
              <td>19.55</td>
              <td>46.65</td>
              <td>32.93</td>
              <td>33.43</td>
              <td>23.73</td>
              <td>57.00</td>
              <td>30.20</td>
              <td>29.70</td>
              <td>6.03</td>
              <td>31.52</td>
              <td>28.41</td>
              <td>23.65</td>
              <td>23.24</td>
              <td>34.57</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>ShareGPT4V-7B</td>
              <td>7.2B</td>
              <td>36.98</td>
              <td>36.37</td>
              <td>43.79</td>
              <td>34.34</td>
              <td>21.54</td>
              <td>38.56</td>
              <td>17.74</td>
              <td>43.71</td>
              <td>33.74</td>
              <td>28.77</td>
              <td>23.60</td>
              <td>45.50</td>
              <td>25.15</td>
              <td>40.34</td>
              <td>20.66</td>
              <td>24.24</td>
              <td>32.78</td>
              <td>25.19</td>
              <td>24.13</td>
              <td>28.29</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>LLAVA-V1.5-7B-xtuner</td>
              <td>7.2B</td>
              <td>37.33</td>
              <td>38.16</td>
              <td>41.33</td>
              <td>36.98</td>
              <td>27.55</td>
              <td>40.59</td>
              <td>30.68</td>
              <td>44.31</td>
              <td>35.77</td>
              <td>34.49</td>
              <td>22.00</td>
              <td>46.00</td>
              <td>23.42</td>
              <td>40.17</td>
              <td>41.31</td>
              <td>34.16</td>
              <td>31.54</td>
              <td>22.88</td>
              <td>26.63</td>
              <td>37.14</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>Emu2-Chat</td>
              <td>37B</td>
              <td>37.44</td>
              <td>37.05</td>
              <td>41.33</td>
              <td>42.45</td>
              <td>25.59</td>
              <td>40.22</td>
              <td>26.92</td>
              <td>43.97</td>
              <td>39.43</td>
              <td>29.37</td>
              <td>26.00</td>
              <td>34.50</td>
              <td>20.45</td>
              <td>39.50</td>
              <td>27.23</td>
              <td>26.53</td>
              <td>32.87</td>
              <td>23.08</td>
              <td>24.84</td>
              <td>28.57</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>LLAVA-V1.5-7B</td>
              <td>7.2B</td>
              <td>37.49</td>
              <td>37.83</td>
              <td>46.84</td>
              <td>28.68</td>
              <td>27.94</td>
              <td>40.41</td>
              <td>20.45</td>
              <td>45.36</td>
              <td>35.37</td>
              <td>28.46</td>
              <td>22.00</td>
              <td>45.50</td>
              <td>22.18</td>
              <td>48.91</td>
              <td>38.97</td>
              <td>30.53</td>
              <td>32.70</td>
              <td>20.96</td>
              <td>23.15</td>
              <td>26.57</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>TransCore-M</td>
              <td>13.4B</td>
              <td>38.10</td>
              <td>38.63</td>
              <td>40.98</td>
              <td>40.19</td>
              <td>22.98</td>
              <td>36.35</td>
              <td>36.24</td>
              <td>45.74</td>
              <td>33.33</td>
              <td>32.23</td>
              <td>25.20</td>
              <td>44.00</td>
              <td>25.53</td>
              <td>38.82</td>
              <td>37.56</td>
              <td>32.06</td>
              <td>32.04</td>
              <td>23.46</td>
              <td>27.17</td>
              <td>30.86</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>LLAVA-V1.5-13b-xtuner</td>
              <td>13.4B</td>
              <td>38.39</td>
              <td>38.28</td>
              <td>46.49</td>
              <td>28.11</td>
              <td>26.24</td>
              <td>38.75</td>
              <td>28.12</td>
              <td>45.15</td><td>36.18</td>
              <td>30.27</td>
              <td>22.00</td>
              <td>48.00</td>
              <td>29.24</td>
              <td>45.55</td>
              <td>50.23</td>
              <td>30.53</td>
              <td>31.46</td>
              <td>21.15</td>
              <td>22.43</td>
              <td>33.71</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>InternVL-Chat-V1.5</td>
              <td>25.5B</td>
              <td>38.80</td>
              <td>39.47</td>
              <td>43.91</td>
              <td>43.77</td>
              <td>31.59</td>
              <td>33.76</td>
              <td>32.78</td>
              <td>45.42</td>
              <td>31.30</td>
              <td>38.10</td>
              <td>34.40</td>
              <td>45.50</td>
              <td>31.47</td>
              <td>45.88</td>
              <td>17.37</td>
              <td>32.44</td>
              <td>33.94</td>
              <td>22.12</td>
              <td>26.45</td>
              <td>31.43</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>XComposer2</td>
              <td>7B</td>
              <td>38.92</td>
              <td>38.97</td>
              <td>42.27</td>
              <td>37.17</td>
              <td>33.81</td>
              <td>40.77</td>
              <td>21.80</td>
              <td>45.56</td>
              <td>37.80</td>
              <td>34.19</td>
              <td>28.00</td>
              <td>58.00</td>
              <td>24.91</td>
              <td>37.65</td>
              <td>36.15</td>
              <td>39.12</td>
              <td>31.21</td>
              <td>23.46</td>
              <td>27.61</td>
              <td>31.14</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>XComposer2-4KHD</td>
              <td>7B</td>
              <td>39.01</td>
              <td>37.60</td>
              <td>40.98</td>
              <td>34.72</td>
              <td>27.15</td>
              <td>39.67</td>
              <td>20.00</td>
              <td>44.26</td>
              <td>34.55</td>
              <td>33.43</td>
              <td>24.00</td>
              <td>43.00</td>
              <td>29.24</td>
              <td>30.59</td>
              <td>42.72</td>
              <td>33.97</td>
              <td>32.78</td>
              <td>22.12</td>
              <td>26.63</td>
              <td>36.86</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>LLAVA-InternLM-7b</td>
              <td>7.6B</td>
              <td>39.13</td>
              <td>38.86</td>
              <td>39.58</td>
              <td>35.28</td>
              <td>31.85</td>
              <td>36.90</td>
              <td>30.23</td>
              <td>46.60</td>
              <td>37.80</td>
              <td>28.77</td>
              <td>25.20</td>
              <td>51.50</td>
              <td>25.90</td>
              <td>38.82</td>
              <td>37.09</td>
              <td>25.95</td>
              <td>32.20</td>
              <td>27.31</td>
              <td>25.74</td>
              <td>29.43</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>InternVL-Chat-V1.1</td>
              <td>19B</td>
              <td>39.18</td>
              <td>38.86</td>
              <td>43.44</td>
              <td>45.66</td>
              <td>35.90</td>
              <td>46.13</td>
              <td>21.50</td>
              <td>45.96</td>
              <td>35.37</td>
              <td>29.37</td>
              <td>29.60</td>
              <td>39.00</td>
              <td>29.74</td>
              <td>41.18</td>
              <td>17.37</td>
              <td>35.88</td>
              <td>29.56</td>
              <td>20.77</td>
              <td>23.77</td>
              <td>28.29</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>OmniLMM-12B</td>
              <td>12B</td>
              <td>39.41</td>
              <td>38.53</td>
              <td>42.62</td>
              <td>40.94</td>
              <td>29.90</td>
              <td>38.01</td>
              <td>24.36</td>
              <td>46.31</td>
              <td>33.74</td>
              <td>33.73</td>
              <td>28.40</td>
              <td>57.50</td>
              <td>26.27</td>
              <td>34.62</td>
              <td>17.84</td>
              <td>19.85</td>
              <td>30.97</td>
              <td>23.46</td>
              <td>27.17</td>
              <td>36.29</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>Monkey-Chat</td>
              <td>9.8B</td>
              <td>39.76</td>
              <td>38.74</td>
              <td>42.39</td>
              <td>39.43</td>
              <td>33.68</td>
              <td>34.32</td>
              <td>22.26</td>
              <td>47.38</td>
              <td>28.05</td>
              <td>32.08</td>
              <td>27.60</td>
              <td>42.50</td>
              <td>31.72</td>
              <td>31.09</td>
              <td>26.76</td>
              <td>28.24</td>
              <td>33.36</td>
              <td>21.73</td>
              <td>20.64</td>
              <td>31.14</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>DeepSeek-VL-1.3B</td>
              <td>1.3B</td>
              <td>39.92</td>
              <td>40.79</td>
              <td>38.76</td>
              <td>39.43</td>
              <td>36.29</td>
              <td>39.30</td>
              <td>27.37</td>
              <td>48.51</td>
              <td>32.93</td>
              <td>31.93</td>
              <td>23.60</td>
              <td>49.50</td>
              <td>37.67</td>
              <td>44.20</td>
              <td>39.44</td>
              <td>39.69</td>
              <td>32.87</td>
              <td>24.81</td>
              <td>21.36</td>
              <td>29.71</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>MiniCPM-V</td>
              <td>2.8B</td>
              <td>40.05</td>
              <td>41.26</td>
              <td>38.88</td>
              <td>42.26</td>
              <td>30.81</td>
              <td>41.51</td>
              <td>23.01</td>
              <td>48.71</td>
              <td>32.93</td>
              <td>37.20</td>
              <td>26.00</td>
              <td>49.00</td>
              <td>40.02</td>
              <td>44.03</td>
              <td>31.92</td>
              <td>46.56</td>
              <td>33.61</td>
              <td>22.88</td>
              <td>23.15</td>
              <td>34.86</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>InternVL-Chat-V1.2</td>
              <td>40B</td>
              <td>40.53</td>
              <td>39.31</td>
              <td>41.92</td>
              <td>36.79</td>
              <td>26.89</td>
              <td>37.82</td>
              <td>34.59</td>
              <td>46.71</td>
              <td>36.18</td>
              <td>34.34</td>
              <td>20.00</td>
              <td>47.00</td>
              <td>28.50</td>
              <td>44.87</td>
              <td>20.19</td>
              <td>31.49</td>
              <td>34.43</td>
              <td>24.81</td>
              <td>24.40</td>
              <td>26.86</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>InternVL-Chat-V1.2-Plus</td>
              <td>40B</td>
              <td>41.49</td>
              <td>39.87</td>
              <td>44.96</td>
              <td>34.72</td>
              <td>30.94</td>
              <td>36.16</td>
              <td>30.83</td>
              <td>46.91</td>
              <td>41.46</td>
              <td>35.54</td>
              <td>20.40</td>
              <td>51.00</td>
              <td>31.47</td>
              <td>46.55</td>
              <td>15.96</td>
              <td>36.07</td>
              <td>34.02</td>
              <td>23.46</td>
              <td>24.40</td>
              <td>30.00</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>MiniCPM-V2</td>
              <td>2.8B</td>
              <td>41.95</td>
              <td>42.24</td>
              <td>41.57</td>
              <td>40.75</td>
              <td>32.77</td>
              <td>39.67</td>
              <td>28.27</td>
              <td>51.27</td>
              <td>28.46</td>
              <td>32.23</td>
              <td>28.00</td>
              <td>48.50</td>
              <td>35.44</td>
              <td>45.55</td>
              <td>31.46</td>
              <td>46.56</td>
              <td>31.05</td>
              <td>23.46</td>
              <td>23.95</td>
              <td>31.14</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>DeepSeek-VL-7B</td>
              <td>7.3B</td>
              <td>42.92</td>
              <td>42.96</td>
              <td>39.46</td>
              <td>43.02</td>
              <td>42.04</td>
              <td>37.82</td>
              <td>26.62</td>
              <td>50.64</td>
              <td>31.30</td>
              <td>31.17</td>
              <td>25.20</td>
              <td>47.50</td>
              <td>33.95</td>
              <td>57.48</td>
              <td>53.99</td>
              <td>45.61</td>
              <td>34.52</td>
              <td>18.46</td>
              <td>25.65</td>
              <td>38.00</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>LLAVA-InternLM2-7b</td>
              <td>8.1B</td>
              <td><u>48.35</u></td>
              <td><u>50.45</u></td>
              <td><b>54.10</b></td>
              <td>39.43</td>
              <td>39.69</td>
              <td>34.32</td>
              <td><u>42.71</u></td>
              <td><b>61.57</b></td>
              <td><u>39.84</u></td>
              <td><b>64.16</b></td>
              <td>21.20</td>
              <td>55.50</td>
              <td>44.24</td>
              <td>42.18</td>
              <td><b>46.01</b></td>
              <td>40.46</td>
              <td><b>36.42</b></td>
              <td>23.65</td>
              <td>24.40</td>
              <td><b>46.86</b></td>
            </tr>
            <tr>
              <td colspan="22" style="text-align: center;">Proprietary VLMs</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
              <td>Claude3-Opus</td>
              <td>-</td>
              <td>34.03</td>
              <td>31.67</td>
              <td>1.52</td>
              <td>33.58</td>
              <td>30.81</td>
              <td>32.10</td>
              <td>10.53</td>
              <td>39.75</td>
              <td>26.83</td>
              <td>31.63</td>
              <td>23.20</td>
              <td>39.50</td>
              <td>19.21</td>
              <td>43.19</td>
              <td>24.88</td>
              <td>29.39</td>
              <td>29.15</td>
              <td>22.88</td>
              <td>22.52</td>
              <td>4.57</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
              <td>Qwen-VL-Max</td>
              <td>-</td>
              <td>43.69</td>
              <td>41.10</td>
              <td>35.25</td>
              <td>40.00</td>
              <td>33.29</td>
              <td>40.22</td>
              <td>11.13</td>
              <td>50.04</td>
              <td>31.71</td>
              <td>43.83</td>
              <td>32.00</td>
              <td>54.50</td>
              <td>34.32</td>
              <td>58.49</td>
              <td>11.27</td>
              <td>36.26</td>
              <td>26.26</td>
              <td>25.38</td>
              <td>24.22</td>
              <td>38.29</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
              <td>Gemini 1.0</td>
              <td>-</td>
              <td>45.12</td>
              <td>44.60</td>
              <td>42.86</td>
              <td>40.75</td>
              <td>41.91</td>
              <td>35.98</td>
              <td>21.05</td>
              <td>53.25</td>
              <td>34.96</td>
              <td>37.80</td>
              <td>29.20</td>
              <td>49.00</td>
              <td>36.06</td>
              <td>61.34</td>
              <td>36.62</td>
              <td>50.76</td>
              <td>34.76</td>
              <td><u>25.58</u></td>
              <td>23.86</td>
              <td>35.14</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
              <td>GPT-4V</td>
              <td>-</td>
              <td>45.50</td>
              <td>43.09</td>
              <td>32.79</td>
              <td>41.89</td>
              <td>42.82</td>
              <td>35.42</td>
              <td>13.68</td>
              <td>52.14</td>
              <td>31.71</td>
              <td>45.48</td>
              <td>33.20</td>
              <td>58.50</td>
              <td>36.18</td>
              <td>58.15</td>
              <td>32.39</td>
              <td>47.52</td>
              <td>25.68</td>
              <td>23.85</td>
              <td>25.38</td>
              <td>38.29</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
              <td>Gemini 1.5</td>
              <td>-</td>
              <td>48.18</td>
              <td>48.17</td>
              <td><u>45.20</u></td>
              <td><u>52.26</u></td>
              <td><u>50.78</u></td>
              <td><u>43.73</u></td>
              <td>2.56</td>
              <td>55.49</td>
              <td>39.02</td>
              <td>51.36</td>
              <td><b>36.40</b></td>
              <td><b>78.50</b></td>
              <td><u>48.95</u></td>
              <td><b>80.50</b></td>
              <td><u>43.19</u></td>
              <td><b>70.23</b></td>
              <td>19.32</td>
              <td><b>27.88</b></td>
              <td><u>29.58</u></td>
              <td>39.14</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
              <td>GPT-4o</td>
              <td>-</td>
              <td><b>55.32</b></td>
              <td><b>53.56</b></td>
              <td>41.92</td>
              <td><b>53.77</b></td>
              <td><b>56.27</b></td>
              <td><b>47.42</b></td>
              <td><b>46.77</b></td>
              <td><u>61.40</u></td>
              <td><b>46.34</b></td>
              <td><u>57.68</u></td>
              <td><u>33.60</u></td>
              <td><u>75.00</u></td>
              <td><b>54.28</b></td>
              <td><u>71.76</u></td>
              <td>39.44</td>
              <td><u>64.89</u></td>
              <td><u>33.20</u></td>
              <td>23.85</td>
              <td><b>29.94</b></td>
              <td><u>40.57</u></td>
            </tr>
          </table>
          <table id="table2" class="js-sort-table hidden">
            <tr>
              <td class="js-sort-string"><strong>Model name</strong></td>
              <td class="js-sort-string"><strong>Size</strong></td>
              <td class="js-sort-number"><strong>Overall (val)</strong></td>
              <td class="js-sort-number"><strong>Overall (test)</strong></td>
              <td class="js-sort-number"><strong>CS</strong></td>
              <td class="js-sort-number"><strong>D</strong></td>
              <td class="js-sort-number"><strong>E</strong></td>
              <td class="js-sort-number"><strong>GH</strong></td>
              <td class="js-sort-number"><strong>GS</strong></td>
              <td class="js-sort-number"><strong>H</strong></td>
              <td class="js-sort-number"><strong>ID</strong></td>
              <td class="js-sort-number"><strong>LMP</strong></td>
              <td class="js-sort-number"><strong>NH</strong></td>
              <td class="js-sort-number"><strong>N</strong></td>
              <td class="js-sort-number"><strong>OG</strong></td>
              <td class="js-sort-number"><strong>OM</strong></td>
              <td class="js-sort-number"><strong>O</strong></td>
              <td class="js-sort-number"><strong>OS</strong></td>
              <td class="js-sort-number"><strong>ENT/HNS</strong></td>
              <td class="js-sort-number"><strong>PM</strong></td>
              <td class="js-sort-number"><strong>SM</strong></td>
              <td class="js-sort-number"><strong>U</strong></td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
              <td>Random</td>
              <td>-</td>
              <td>25.04</td>
              <td>26.17</td>
              <td>26.32</td>
              <td>23.79</td>
              <td>21.74</td>
              <td>26.77</td>
              <td>22.50</td>
              <td>27.40</td>
              <td>33.97</td>
              <td>28.44</td>
              <td>19.29</td>
              <td>23.11</td>
              <td>27.62</td>
              <td>26.80</td>
              <td>29.84</td>
              <td>25.21</td>
              <td>26.56</td>
              <td>23.40</td>
              <td>23.12</td>
              <td>31.18</td>
            </tr>
            <tr>
              <td colspan="22" style="text-align: center;">Medical Special Model</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
              <td>MedVInT</td>
              <td>-</td>
              <td>2.10</td>
              <td>1.92</td>
              <td>0.00</td>
              <td>2.07</td>
              <td>0.87</td>
              <td>2.45</td>
              <td>1.13</td>
              <td>0.81</td>
              <td>2.56</td>
              <td>4.44</td>
              <td>0.96</td>
              <td>0.44</td>
              <td>0.00</td>
              <td>1.63</td>
              <td>4.37</td>
              <td>0.79</td>
              <td>0.21</td>
              <td>1.88</td>
              <td>0.75</td>
              <td>0.82</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
              <td>Med-Flamingo</td>
              <td>8.3B</td>
              <td>10.94</td>
              <td>12.02</td>
              <td>11.40</td>
              <td>13.56</td>
              <td>11.30</td>
              <td>11.16</td>
              <td>9.33</td>
              <td>5.86</td>
              <td>7.69</td>
              <td>9.65</td>
              <td>9.65</td>
              <td>13.78</td>
              <td>13.08</td>
              <td>16.26</td>
              <td>14.90</td>
              <td>13.61</td>
              <td>13.07</td>
              <td>12.99</td>
              <td>15.93</td>
              <td>10.16</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
              <td>LLaVA-Med</td>
              <td>-</td>
              <td>18.78</td>
              <td>20.20</td>
              <td>27.19</td>
              <td>21.38</td>
              <td>31.30</td>
              <td>21.03</td>
              <td>17.67</td>
              <td>17.46</td>
              <td>16.67</td>
              <td>20.50</td>
              <td>23.47</td>
              <td>16.44</td>
              <td>21.22</td>
              <td>19.90</td>
              <td>21.20</td>
              <td>20.66</td>
              <td>21.37</td>
              <td>17.23</td>
              <td>21.78</td>
              <td>20.74</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
              <td>Qilin-Med-VL-Chat</td>
              <td>-</td>
              <td>21.29</td>
              <td>22.35</td>
              <td>14.47</td>
              <td>20.11</td>
              <td>20.43</td>
              <td>24.58</td>
              <td>18.47</td>
              <td>18.75</td>
              <td>21.15</td>
              <td>21.61</td>
              <td>35.37</td>
              <td>28.00</td>
              <td>18.90</td>
              <td>21.60</td>
              <td>24.96</td>
              <td>19.62</td>
              <td>17.22</td>
              <td>29.09</td>
              <td>21.49</td>
              <td>21.15</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
              <td>RadFM</td>
              <td>14B</td>
              <td>22.60</td>
              <td>23.06</td>
              <td>19.74</td>
              <td>23.56</td>
              <td>23.04</td>
              <td>22.39</td>
              <td>20.58</td>
              <td>21.49</td>
              <td>28.85</td>
              <td>24.77</td>
              <td>18.01</td>
              <td>32.89</td>
              <td>15.99</td>
              <td>26.73</td>
              <td>25.67</td>
              <td>18.04</td>
              <td>24.69</td>
              <td>25.28</td>
              <td>23.46</td>
              <td>19.92</td>
            </tr>
            <tr style="background-color: rgba(255, 208, 80, 0.15);">
              <td>MedDr</td>
              <td>40B</td>
              <td>43.41</td>
              <td>43.12</td>
              <td>56.14</td>
              <td>45.63</td>
              <td>38.70</td>
              <td>46.77</td>
              <td>27.29</td>
              <td>29.23</td>
              <td>46.15</td>
              <td>32.96</td>
              <td>35.69</td>
              <td>84.44</td>
              <td>23.84</td>
              <td>48.40</td>
              <td>44.69</td>
              <td>50.00</td>
              <td>52.70</td>
              <td>51.91</td>
              <td>54.58</td>
              <td>36.95</td>
            </tr>
            <tr>
              <td colspan="22" style="text-align: center;">Open-Source VLMs</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>CogVLM-grounding-generalist</td>
              <td>17B</td>
              <td>5.09</td>
              <td>5.52</td>
              <td>5.70</td>
              <td>7.36</td>
              <td>6.09</td>
              <td>4.39</td>
              <td>3.23</td>
              <td>4.30</td>
              <td>5.13</td>
              <td>2.05</td>
              <td>21.54</td>
              <td>23.11</td>
              <td>6.10</td>
              <td>8.46</td>
              <td>4.42</td>
              <td>4.86</td>
              <td>7.47</td>
              <td>7.41</td>
              <td>4.35</td>
              <td>3.02</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>XComposer</td>
              <td>8B</td>
              <td>7.43</td>
              <td>7.80</td>
              <td>18.42</td>
              <td>2.99</td>
              <td>7.39</td>
              <td>5.29</td>
              <td>4.31</td>
              <td>11.34</td>
              <td>2.56</td>
              <td>6.23</td>
              <td>3.54</td>
              <td>29.33</td>
              <td>4.94</td>
              <td>8.54</td>
              <td>10.22</td>
              <td>8.69</td>
              <td>6.64</td>
              <td>8.05</td>
              <td>10.08</td>
              <td>5.08</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>PandaGPT 13B</td>
              <td>13B</td>
              <td>17.90</td>
              <td>15.35</td>
              <td>9.21</td>
              <td>12.53</td>
              <td>16.09</td>
              <td>15.29</td>
              <td>11.49</td>
              <td>13.92</td>
              <td>24.36</td>
              <td>16.48</td>
              <td>16.40</td>
              <td>11.11</td>
              <td>9.30</td>
              <td>14.33</td>
              <td>23.03</td>
              <td>13.55</td>
              <td>14.73</td>
              <td>17.77</td>
              <td>13.62</td>
              <td>10.71</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>Flamingo v2</td>
              <td>9B</td>
              <td>25.61</td>
              <td>26.44</td>
              <td>34.65</td>
              <td>27.13</td>
              <td>19.13</td>
              <td>28.32</td>
              <td>20.16</td>
              <td>25.58</td>
              <td>31.41</td>
              <td>26.22</td>
              <td>10.29</td>
              <td>34.67</td>
              <td>23.26</td>
              <td>28.43</td>
              <td>32.18</td>
              <td>23.63</td>
              <td>25.93</td>
              <td>24.21</td>
              <td>28.22</td>
              <td>29.81</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>VisualGLM-6B</td>
              <td>7.8B</td>
              <td>29.34</td>
              <td>30.48</td>
              <td>51.75</td>
              <td>26.55</td>
              <td>16.09</td>
              <td>33.42</td>
              <td>21.57</td>
              <td>25.09</td>
              <td>31.41</td>
              <td>24.51</td>
              <td>33.44</td>
              <td>68.00</td>
              <td>21.51</td>
              <td>30.14</td>
              <td>36.10</td>
              <td>30.68</td>
              <td>28.84</td>
              <td>34.84</td>
              <td>37.31</td>
              <td>21.70</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>Idefics-9B-Instruct</td>
              <td>9B</td>
              <td>29.63</td>
              <td>31.18</td>
              <td>16.23</td>
              <td>33.91</td>
              <td>23.04</td>
              <td>30.58</td>
              <td>24.80</td>
              <td>26.54</td>
              <td>46.79</td>
              <td>27.92</td>
              <td>35.69</td>
              <td>70.67</td>
              <td>38.95</td>
              <td>28.66</td>
              <td>33.96</td>
              <td>36.39</td>
              <td>23.24</td>
              <td>31.88</td>
              <td>32.50</td>
              <td>28.98</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>InstructBLIP-7B</td>
              <td>8B</td>
              <td>30.25</td>
              <td>31.20</td>
              <td>23.25</td>
              <td>28.62</td>
              <td>20.00</td>
              <td>34.84</td>
              <td>20.07</td>
              <td>26.54</td>
              <td>40.38</td>
              <td>28.18</td>
              <td>21.86</td>
              <td>61.33</td>
              <td>25.00</td>
              <td>27.69</td>
              <td>31.57</td>
              <td>34.63</td>
              <td>37.34</td>
              <td>32.26</td>
              <td>42.76</td>
              <td>28.85</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>Mini-Gemini-7B</td>
              <td>7B</td>
              <td>31.55</td>
              <td>31.17</td>
              <td>38.16</td>
              <td>40.69</td>
              <td>27.83</td>
              <td>36.52</td>
              <td>24.19</td>
              <td>19.34</td>
              <td>40.38</td>
              <td>25.19</td>
              <td>42.12</td>
              <td>63.11</td>
              <td>22.97</td>
              <td>20.49</td>
              <td>35.33</td>
              <td>33.84</td>
              <td>39.21</td>
              <td>41.71</td>
              <td>29.37</td>
              <td>25.27</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>MMAlaya</td>
              <td>7.8B</td>
              <td>32.81</td>
              <td>31.86</td>
              <td>82.02</td>
              <td>38.16</td>
              <td>35.65</td>
              <td>26.84</td>
              <td>25.74</td>
              <td>32.62</td>
              <td>48.72</td>
              <td>30.49</td>
              <td>27.01</td>
              <td>90.22</td>
              <td>26.45</td>
              <td>27.84</td>
              <td>34.62</td>
              <td>35.54</td>
              <td>21.37</td>
              <td>26.84</td>
              <td>30.36</td>
              <td>22.39</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>Yi-VL-6B</td>
              <td>6.6B</td>
              <td>33.27</td>
              <td>34.33</td>
              <td>28.07</td>
              <td>45.06</td>
              <td>49.13</td>
              <td>27.16</td>
              <td>26.77</td>
              <td>26.65</td>
              <td>44.87</td>
              <td>30.91</td>
              <td>45.02</td>
              <td>72.89</td>
              <td>53.20</td>
              <td>35.86</td>
              <td>37.72</td>
              <td>35.60</td>
              <td>31.33</td>
              <td>30.43</td>
              <td>38.99</td>
              <td>31.32</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>LLaVA-NeXT-vicuna-7B</td>
              <td>7.1B</td>
              <td>34.59</td>
              <td>35.25</td>
              <td>32.27</td>
              <td>38.39</td>
              <td>55.56</td>
              <td>32.41</td>
              <td>28.22</td>
              <td>27.07</td>
              <td>48.72</td>
              <td>29.21</td>
              <td>28.41</td>
              <td>84.89</td>
              <td>30.62</td>
              <td>35.20</td>
              <td>43.37</td>
              <td>37.81</td>
              <td>29.61</td>
              <td>38.44</td>
              <td>37.44</td>
              <td>25.50</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>CogVLM-Chat</td>
              <td>17B</td>
              <td>35.46</td>
              <td>35.97</td>
              <td>20.61</td>
              <td>40.80</td>
              <td>43.04</td>
              <td>32.39</td>
              <td>24.94</td>
              <td>25.20</td>
              <td>46.79</td>
              <td>33.99</td>
              <td>46.95</td>
              <td>65.33</td>
              <td>31.69</td>
              <td>43.36</td>
              <td>38.33</td>
              <td>37.48</td>
              <td>35.06</td>
              <td>39.67</td>
              <td>44.90</td>
              <td>27.06</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>Qwen-7B</td>
              <td>9.6B</td>
              <td>35.58</td>
              <td>35.58</td>
              <td>40.35</td>
              <td>40.00</td>
              <td>37.83</td>
              <td>30.52</td>
              <td>20.58</td>
              <td>26.01</td>
              <td>46.79</td>
              <td>28.35</td>
              <td>55.95</td>
              <td>79.56</td>
              <td>40.12</td>
              <td>39.42</td>
              <td>38.89</td>
              <td>40.95</td>
              <td>33.40</td>
              <td>35.70</td>
              <td>44.84</td>
              <td>40.80</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>mPLUG-Owl2</td>
              <td>8.2B</td>
              <td>36.07</td>
              <td>35.86</td>
              <td>45.61</td>
              <td>41.49</td>
              <td>47.39</td>
              <td>33.10</td>
              <td>25.83</td>
              <td>28.96</td>
              <td>51.92</td>
              <td>31.00</td>
              <td>31.19</td>
              <td>79.11</td>
              <td>19.19</td>
              <td>37.27</td>
              <td>42.55</td>
              <td>36.15</td>
              <td>33.61</td>
              <td>41.12</td>
              <td>40.67</td>
              <td>24.45</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>Monkey</td>
              <td>9.8B</td>
              <td>36.24</td>
              <td>35.85</td>
              <td>39.04</td>
              <td>39.54</td>
              <td>34.78</td>
              <td>29.87</td>
              <td>20.30</td>
              <td>26.38</td>
              <td>51.28</td>
              <td>27.16</td>
              <td>45.98</td>
              <td>77.78</td>
              <td>33.72</td>
              <td>38.60</td>
              <td>40.57</td>
              <td>43.74</td>
              <td>33.20</td>
              <td>39.29</td>
              <td>44.84</td>
              <td>40.93</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>ShareCaptioner</td>
              <td>8B</td>
              <td>36.34</td>
              <td>35.96</td>
              <td>35.96</td>
              <td>35.52</td>
              <td>47.83</td>
              <td>35.23</td>
              <td>24.29</td>
              <td>28.26</td>
              <td>53.85</td>
              <td>31.85</td>
              <td>24.44</td>
              <td>73.78</td>
              <td>34.59</td>
              <td>39.20</td>
              <td>39.30</td>
              <td>39.00</td>
              <td>35.68</td>
              <td>42.40</td>
              <td>37.08</td>
              <td>34.89</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>Qwen-7B-Chat</td>
              <td>9.6B</td>
              <td>36.63</td>
              <td>36.32</td>
              <td>35.53</td>
              <td>38.74</td>
              <td>33.48</td>
              <td>28.06</td>
              <td>21.05</td>
              <td>28.69</td>
              <td>55.77</td>
              <td>28.10</td>
              <td>51.77</td>
              <td>78.22</td>
              <td>36.05</td>
              <td>43.88</td>
              <td>38.38</td>
              <td>44.71</td>
              <td>31.54</td>
              <td>37.04</td>
              <td>47.97</td>
              <td>36.68</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>LLaVA-NeXT-mistral-7B</td>
              <td>7.6B</td>
              <td>36.71</td>
              <td>37.06</td>
              <td>37.94</td>
              <td>40.69</td>
              <td>50.74</td>
              <td>39.12</td>
              <td>28.55</td>
              <td>25.89</td>
              <td>48.72</td>
              <td>30.40</td>
              <td>43.18</td>
              <td>87.56</td>
              <td>21.95</td>
              <td>43.46</td>
              <td>42.62</td>
              <td>35.12</td>
              <td>27.08</td>
              <td>46.18</td>
              <td>38.20</td>
              <td>25.50</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>ShareGPT4V-7B</td>
              <td>7.2B</td>
              <td>36.98</td>
              <td>36.37</td>
              <td>42.11</td>
              <td>41.26</td>
              <td>54.35</td>
              <td>36.90</td>
              <td>26.44</td>
              <td>23.97</td>
              <td>46.15</td>
              <td>29.63</td>
              <td>39.23</td>
              <td>75.56</td>
              <td>32.85</td>
              <td>42.84</td>
              <td>43.87</td>
              <td>37.36</td>
              <td>35.68</td>
              <td>37.14</td>
              <td>36.85</td>
              <td>31.46</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>LLAVA-V1.5-7B-xtuner</td>
              <td>7.2B</td>
              <td>37.33</td>
              <td>38.16</td>
              <td>45.18</td>
              <td>36.09</td>
              <td>33.91</td>
              <td>38.45</td>
              <td>29.72</td>
              <td>31.33</td>
              <td>54.49</td>
              <td>35.95</td>
              <td>23.15</td>
              <td>82.22</td>
              <td>33.14</td>
              <td>49.37</td>
              <td>40.77</td>
              <td>39.61</td>
              <td>31.74</td>
              <td>40.47</td>
              <td>39.92</td>
              <td>31.87</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>Emu2-Chat</td>
              <td>37B</td>
              <td>37.44</td>
              <td>37.05</td>
              <td>17.98</td>
              <td>35.75</td>
              <td>35.65</td>
              <td>31.94</td>
              <td>27.05</td>
              <td>28.91</td>
              <td>57.05</td>
              <td>35.44</td>
              <td>29.58</td>
              <td>73.78</td>
              <td>34.59</td>
              <td>43.36</td>
              <td>42.96</td>
              <td>38.40</td>
              <td>38.80</td>
              <td>41.92</td>
              <td>43.97</td>
              <td>30.91</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>LLAVA-V1.5-7B</td>
              <td>7.2B</td>
              <td>37.49</td>
              <td>37.83</td>
              <td>39.47</td>
              <td>39.54</td>
              <td>54.78</td>
              <td>35.61</td>
              <td>26.11</td>
              <td>24.99</td>
              <td>45.51</td>
              <td>30.83</td>
              <td>29.58</td>
              <td>78.22</td>
              <td>30.52</td>
              <td>44.77</td>
              <td>42.20</td>
              <td>42.10</td>
              <td>40.66</td>
              <td>43.75</td>
              <td>41.77</td>
              <td>35.16</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>TransCore-M</td>
              <td>13.4B</td>
              <td>38.10</td>
              <td>38.63</td>
              <td>38.16</td>
              <td>45.40</td>
              <td>28.26</td>
              <td>38.00</td>
              <td>28.93</td>
              <td>32.35</td>
              <td>51.92</td>
              <td>31.43</td>
              <td>36.01</td>
              <td>75.11</td>
              <td>48.84</td>
              <td>40.31</td>
              <td>43.42</td>
              <td>40.64</td>
              <td>41.08</td>
              <td>34.62</td>
              <td>47.68</td>
              <td>32.14</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>LLAVA-V1.5-13b-xtuner</td>
              <td>13.4B</td>
              <td>38.39</td>
              <td>38.28</td>
              <td>30.70</td>
              <td>41.49</td>
              <td>40.43</td>
              <td>41.48</td>
              <td>25.69</td>
              <td>27.67</td>
              <td>48.08</td>
              <td>33.82</td>
              <td>30.87</td>
              <td>84.00</td>
              <td>43.60</td>
              <td>50.71</td>
              <td>41.64</td>
              <td>34.08</td>
              <td>41.08</td>
              <td>41.76</td>
              <td>41.02</td>
              <td>36.68</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>InternVL-Chat-V1.5</td>
              <td>25.5B</td>
              <td>38.80</td>
              <td>39.47</td>
              <td>35.96</td>
              <td>45.75</td>
              <td>51.30</td>
              <td>36.39</td>
              <td>26.96</td>
              <td>32.78</td>
              <td>59.62</td>
              <td>31.68</td>
              <td>37.30</td>
              <td>80.44</td>
              <td>35.47</td>
              <td>53.97</td>
              <td>46.67</td>
              <td>38.52</td>
              <td>44.40</td>
              <td>38.49</td>
              <td>38.18</td>
              <td>36.26</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>XComposer2</td>
              <td>7B</td>
              <td>38.92</td>
              <td>38.97</td>
              <td>30.26</td>
              <td>43.22</td>
              <td>64.78</td>
              <td>32.39</td>
              <td>28.93</td>
              <td>28.37</td>
              <td>52.56</td>
              <td>32.11</td>
              <td>25.08</td>
              <td>91.11</td>
              <td>38.37</td>
              <td>45.95</td>
              <td>43.52</td>
              <td>45.32</td>
              <td>35.06</td>
              <td>44.77</td>
              <td>41.37</td>
              <td>34.20</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>XComposer2-4KHD</td>
              <td>7B</td>
              <td>39.01</td>
              <td>37.60</td>
              <td>44.74</td>
              <td>42.41</td>
              <td>73.91</td>
              <td>36.39</td>
              <td>28.04</td>
              <td>27.51</td>
              <td>48.08</td>
              <td>34.16</td>
              <td>46.30</td>
              <td>75.56</td>
              <td>37.21</td>
              <td>37.64</td>
              <td>42.86</td>
              <td>38.34</td>
              <td>31.54</td>
              <td>42.14</td>
              <td>34.41</td>
              <td>37.91</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>LLAVA-InternLM-7b</td>
              <td>7.6B</td>
              <td>39.13</td>
              <td>38.86</td>
              <td>41.67</td>
              <td>38.97</td>
              <td>40.00</td>
              <td>44.39</td>
              <td>28.69</td>
              <td>26.97</td>
              <td>48.08</td>
              <td>33.48</td>
              <td>28.62</td>
              <td>93.78</td>
              <td>43.60</td>
              <td>46.10</td>
              <td>42.50</td>
              <td>39.13</td>
              <td>38.38</td>
              <td>37.20</td>
              <td>46.87</td>
              <td>34.34</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>InternVL-Chat-V1.1</td>
              <td>19B</td>
              <td>39.18</td>
              <td>38.86</td>
              <td>41.23</td>
              <td>39.54</td>
              <td>54.35</td>
              <td>35.87</td>
              <td>25.32</td>
              <td>27.19</td>
              <td>50.00</td>
              <td>36.64</td>
              <td>39.55</td>
              <td>76.00</td>
              <td>35.47</td>
              <td>50.11</td>
              <td>43.42</td>
              <td>41.98</td>
              <td>42.32</td>
              <td>40.26</td>
              <td>44.96</td>
              <td>29.95</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>OmniLMM-12B</td>
              <td>12B</td>
              <td>39.41</td>
              <td>38.53</td>
              <td>29.82</td>
              <td>36.90</td>
              <td>44.78</td>
              <td>37.35</td>
              <td>26.68</td>
              <td>27.62</td>
              <td>57.69</td>
              <td>33.90</td>
              <td>51.13</td>
              <td>87.11</td>
              <td>30.81</td>
              <td>33.18</td>
              <td>43.42</td>
              <td>40.77</td>
              <td>33.40</td>
              <td>43.59</td>
              <td>51.33</td>
              <td>36.68</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>Monkey-Chat</td>
              <td>9.8B</td>
              <td>39.76</td>
              <td>38.74</td>
              <td>41.23</td>
              <td>40.34</td>
              <td>40.00</td>
              <td>33.29</td>
              <td>21.94</td>
              <td>29.50</td>
              <td>51.92</td>
              <td>28.95</td>
              <td>51.13</td>
              <td>82.22</td>
              <td>35.47</td>
              <td>48.26</td>
              <td>41.69</td>
              <td>44.71</td>
              <td>33.61</td>
              <td>41.92</td>
              <td>49.77</td>
              <td>41.07</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>DeepSeek-VL-1.3B</td>
              <td>1.3B</td>
              <td>39.92</td>
              <td>40.79</td>
              <td>57.89</td>
              <td>38.05</td>
              <td>33.04</td>
              <td>46.71</td>
              <td>27.24</td>
              <td>29.93</td>
              <td>53.85</td>
              <td>34.33</td>
              <td>45.34</td>
              <td>79.56</td>
              <td>47.09</td>
              <td>49.81</td>
              <td>41.48</td>
              <td>46.60</td>
              <td>40.46</td>
              <td>44.34</td>
              <td>45.25</td>
              <td>32.14</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>MiniCPM-V</td>
              <td>2.8B</td>
              <td>40.05</td>
              <td>41.26</td>
              <td>23.68</td>
              <td>42.53</td>
              <td>41.74</td>
              <td>45.48</td>
              <td>28.41</td>
              <td>29.07</td>
              <td>42.95</td>
              <td>36.38</td>
              <td>41.80</td>
              <td>77.33</td>
              <td>38.37</td>
              <td>41.05</td>
              <td>43.82</td>
              <td>46.90</td>
              <td>42.53</td>
              <td>50.83</td>
              <td>52.78</td>
              <td>26.37</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>InternVL-Chat-V1.2</td>
              <td>40B</td>
              <td>40.53</td>
              <td>39.31</td>
              <td>42.98</td>
              <td>46.78</td>
              <td>79.57</td>
              <td>30.39</td>
              <td>26.44</td>
              <td>30.09</td>
              <td>48.72</td>
              <td>35.53</td>
              <td>48.87</td>
              <td>80.00</td>
              <td>29.65</td>
              <td>44.02</td>
              <td>42.35</td>
              <td>39.73</td>
              <td>38.17</td>
              <td>42.35</td>
              <td>46.41</td>
              <td>37.77</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>InternVL-Chat-V1.2-Plus</td>
              <td>40B</td>
              <td>41.49</td>
              <td>39.87</td>
              <td>50.44</td>
              <td>44.02</td>
              <td>64.35</td>
              <td>36.71</td>
              <td>29.72</td>
              <td>29.77</td>
              <td>51.28</td>
              <td>37.49</td>
              <td>54.02</td>
              <td>79.56</td>
              <td>31.10</td>
              <td>47.96</td>
              <td>42.96</td>
              <td>37.55</td>
              <td>41.29</td>
              <td>40.20</td>
              <td>43.97</td>
              <td>34.48</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>MiniCPM-V2</td>
              <td>2.8B</td>
              <td>41.95</td>
              <td>42.24</td>
              <td>29.82</td>
              <td>44.02</td>
              <td>36.52</td>
              <td>40.97</td>
              <td>27.19</td>
              <td>29.61</td>
              <td>35.26</td>
              <td>31.85</td>
              <td>60.77</td>
              <td>77.78</td>
              <td>43.31</td>
              <td>47.36</td>
              <td>42.96</td>
              <td>48.42</td>
              <td>45.23</td>
              <td>50.19</td>
              <td>58.69</td>
              <td>32.01</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>DeepSeek-VL-7B</td>
              <td>7.3B</td>
              <td>42.92</td>
              <td>42.96</td>
              <td>64.47</td>
              <td>43.79</td>
              <td>50.00</td>
              <td>45.94</td>
              <td>27.10</td>
              <td>30.25</td>
              <td>45.51</td>
              <td>31.68</td>
              <td>46.30</td>
              <td>76.00</td>
              <td>64.83</td>
              <td>47.66</td>
              <td>44.23</td>
              <td>49.76</td>
              <td>56.43</td>
              <td>44.07</td>
              <td>52.72</td>
              <td>37.64</td>
            </tr>
            <tr style="background-color: rgba(117, 209, 215, 0.1);">
              <td>LLAVA-InternLM2-7b</td>
              <td>8.1B</td>
              <td><u>48.35</u></td>
              <td><u>50.45</u></td>
              <td>45.61</td>
              <td><u>49.43</u></td>
              <td><u>70.00</u></td>
              <td>51.48</td>
              <td>33.01</td>
              <td><u>42.99</u></td>
              <td>58.97</td>
              <td><b>50.04</b></td>
              <td>51.45</td>
              <td>90.67</td>
              <td><b>54.65</b></td>
              <td>45.21</td>
              <td><u>51.75</u></td>
              <td><u>57.11</u></td>
              <td>39.00</td>
              <td>53.09</td>
              <td><b>67.67</b></td>
              <td><b>42.86</b></td>
            </tr>
            <tr>
              <td colspan="22" style="text-align: center;">Proprietary VLMs</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
              <td>Claude3-Opus</td>
              <td>-</td>
              <td>34.03</td>
              <td>31.67</td>
              <td>36.84</td>
              <td>34.71</td>
              <td>42.17</td>
              <td>28.39</td>
              <td>21.57</td>
              <td>21.76</td>
              <td>52.56</td>
              <td>24.51</td>
              <td>25.08</td>
              <td>71.56</td>
              <td>22.09</td>
              <td>33.41</td>
              <td>42.25</td>
              <td>35.54</td>
              <td>41.29</td>
              <td>39.45</td>
              <td>35.63</td>
              <td>27.47</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
              <td>Qwen-VL-Max</td>
              <td>-</td>
              <td>43.69</td>
              <td>41.10</td>
              <td>45.61</td>
              <td>46.32</td>
              <td>75.22</td>
              <td>42.32</td>
              <td>27.94</td>
              <td>25.04</td>
              <td>55.77</td>
              <td>32.54</td>
              <td>55.95</td>
              <td>86.22</td>
              <td>26.45</td>
              <td>41.72</td>
              <td>44.64</td>
              <td>43.01</td>
              <td>49.17</td>
              <td>49.06</td>
              <td>51.27</td>
              <td>32.14</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
              <td>Gemini 1.0</td>
              <td>-</td>
              <td>45.12</td>
              <td>44.60</td>
              <td>56.14</td>
              <td>46.90</td>
              <td>57.83</td>
              <td>39.03</td>
              <td>28.83</td>
              <td>28.05</td>
              <td>45.51</td>
              <td>37.40</td>
              <td>59.16</td>
              <td>89.33</td>
              <td>45.93</td>
              <td>47.29</td>
              <td>45.25</td>
              <td>52.61</td>
              <td>55.19</td>
              <td>48.63</td>
              <td>62.80</td>
              <td>37.50</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
              <td>GPT-4V</td>
              <td>-</td>
              <td>45.50</td>
              <td>43.09</td>
              <td>63.60</td>
              <td>43.79</td>
              <td>60.87</td>
              <td>43.03</td>
              <td>29.02</td>
              <td>28.32</td>
              <td><u>60.90</u></td>
              <td>31.00</td>
              <td>54.02</td>
              <td>84.44</td>
              <td>39.24</td>
              <td>44.62</td>
              <td>48.70</td>
              <td>46.78</td>
              <td>49.17</td>
              <td>51.85</td>
              <td>54.23</td>
              <td>33.38</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
              <td>Gemini 1.5</td>
              <td>-</td>
              <td>48.18</td>
              <td>48.17</td>
              <td><u>65.79</u></td>
              <td><b>50.69</b></td>
              <td>59.13</td>
              <td><u>52.06</u></td>
              <td><b>35.21</b></td>
              <td>29.50</td>
              <td>57.69</td>
              <td>37.15</td>
              <td><u>58.52</u></td>
              <td><u>91.56</u></td>
              <td><u>52.62</u></td>
              <td><u>45.36</u></td>
              <td>50.89</td>
              <td>55.65</td>
              <td><b>70.54</b></td>
              <td><u>57.86</u></td>
              <td>60.83</td>
              <td>22.80</td>
            </tr>
            <tr style="background-color: rgba(249, 242, 248, 1);">
              <td>GPT-4o</td>
              <td>-</td>
              <td><b>55.32</b></td>
              <td><b>53.56</b></td>
              <td><b>69.74</b></td>
              <td>46.55</td>
              <td><b>70.43</b></td>
              <td><b>58.13</b></td>
              <td><u>34.41</u></td>
              <td><b>47.88</b></td>
              <td><b>75.64</b></td>
              <td><u>42.53</u></td>
              <td><b>64.95</b></td>
              <td><b>96.44</b></td>
              <td>41.86</td>
              <td><b>55.75</b></td>
              <td><b>55.57</b></td>
              <td><b>61.66</b></td>
              <td><u>68.67</u></td>
              <td><b>58.35</b></td>
              <td><u>64.60</u></td>
              <td><u>40.66</u></td>
            </tr>
          </table>
          <table id="table3" class="js-sort-table hidden">
              <thead>
                <tr>
                  <th>Model name</th>
                  <th>Size</th>
                  <th>Overall(val)</th>
                  <th>Overall(test)</th>
                  <th>Seg C</th>
                  <th>Seg M</th>
                  <th>2D Cls update</th>
                  <th>2D Det</th>
                  <th>2D Mcls_acc</th>
                  <th>2D Mcls_recall</th>
                </tr>
              </thead>
              <tbody>
                <tr>
                  <tr style="background-color: rgba(249, 242, 248, 1);">
                  <td>Random</td>
                  <td>-</td>
                  <td>25.04</td>
                  <td>25.88</td>
                  <td>22.19</td>
                  <td>22.91</td>
                  <td>28.93</td>
                  <td>24.55</td>
                  <td>45.85</td>
                  <td>57.02</td>
                </tr>
                <tr>
                  <td colspan="10" style="text-align: center;">Medical Special Model</td>
                </tr>
                <tr style="background-color: rgba(255, 208, 80, 0.15);">
                  <td>MedVInT</td>
                  <td>-</td>
                  <td>2.10</td>
                  <td>1.98</td>
                  <td>0.82</td>
                  <td>0.25</td>
                  <td>3.48</td>
                  <td>0.12</td>
                  <td>0.05</td>
                  <td>0.02</td>
                </tr>
                <tr style="background-color: rgba(255, 208, 80, 0.15);">
                  <td>Med-Flamingo</td>
                  <td>8.3B</td>
                  <td>10.94</td>
                  <td>11.75</td>
                  <td>11.95</td>
                  <td>11.94</td>
                  <td>11.92</td>
                  <td>9.15</td>
                  <td>46.10</td>
                  <td>50.19</td>
                </tr>
                <tr style="background-color: rgba(255, 208, 80, 0.15);">
                  <td>LLaVA-Med</td>
                  <td>-</td>
                  <td>18.78</td>
                  <td>19.83</td>
                  <td>18.45</td>
                  <td>18.97</td>
                  <td>21.15</td>
                  <td>17.14</td>
                  <td>45.84</td>
                  <td>41.19</td>
                </tr>
                <tr style="background-color: rgba(255, 208, 80, 0.15);">
                  <td>Qilin-Med-VL-Chat</td>
                  <td>-</td>
                  <td>21.29</td>
                  <td>22.06</td>
                  <td>19.84</td>
                  <td>20.30</td>
                  <td>23.80</td>
                  <td>21.87</td>
                  <td>44.50</td>
                  <td>33.90</td>
                </tr>
                <tr style="background-color: rgba(255, 208, 80, 0.15);">
                  <td>RadFM</td>
                  <td>14B</td>
                  <td>22.60</td>
                  <td>22.93</td>
                  <td>20.43</td>
                  <td>20.27</td>
                  <td>25.71</td>
                  <td>18.83</td>
                  <td>40.98</td>
                  <td>57.45</td>
                </tr>
                <tr style="background-color: rgba(255, 208, 80, 0.15);">
                  <td>MedDr</td>
                  <td>40B</td>
                  <td>43.41</td>
                  <td>43.18</td>
                  <td>42.55</td>
                  <td>44.03</td>
                  <td>45.08</td>
                  <td>28.10</td>
                  <td>48.09</td>
                  <td>23.38</td>
                </tr>
                <tr>
                  <td colspan="10" style="text-align: center;">Open-Source VLMs</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>CogVLM-grounding-generalist</td>
                  <td>17B</td>
                  <td>5.09</td>
                  <td>5.39</td>
                  <td>6.80</td>
                  <td>5.51</td>
                  <td>5.11</td>
                  <td>2.57</td>
                  <td>46.24</td>
                  <td>49.82</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>XComposer</td>
                  <td>8B</td>
                  <td>7.43</td>
                  <td>7.71</td>
                  <td>8.87</td>
                  <td>6.24</td>
                  <td>8.02</td>
                  <td>6.30</td>
                  <td>31.45</td>
                  <td>23.68</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>PandaGPT 13B</td>
                  <td>13B</td>
                  <td>17.90</td>
                  <td>15.94</td>
                  <td>19.25</td>
                  <td>18.88</td>
                  <td>13.74</td>
                  <td>12.24</td>
                  <td>41.22</td>
                  <td>49.95</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>Flamingo v2</td>
                  <td>9B</td>
                  <td>25.61</td>
                  <td>26.23</td>
                  <td>22.52</td>
                  <td>22.48</td>
                  <td>30.12</td>
                  <td>21.17</td>
                  <td>41.80</td>
                  <td>19.17</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>VisualGLM-6B</td>
                  <td>7.8B</td>
                  <td>29.34</td>
                  <td>30.20</td>
                  <td>27.30</td>
                  <td>27.31</td>
                  <td>33.75</td>
                  <td>22.16</td>
                  <td>43.08</td>
                  <td>35.22</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>Idefics-9B-Instruct</td>
                  <td>9B</td>
                  <td>29.63</td>
                  <td>30.81</td>
                  <td>25.50</td>
                  <td>25.21</td>
                  <td>36.45</td>
                  <td>23.85</td>
                  <td>43.47</td>
                  <td>46.02</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>InstructBLIP-7B</td>
                  <td>8B</td>
                  <td>30.25</td>
                  <td>31.00</td>
                  <td>29.12</td>
                  <td>21.77</td>
                  <td>36.71</td>
                  <td>24.08</td>
                  <td>39.43</td>
                  <td>23.79</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>Mini-Gemini-7B</td>
                  <td>7B</td>
                  <td>31.55</td>
                  <td>31.22</td>
                  <td>32.13</td>
                  <td>32.92</td>
                  <td>30.72</td>
                  <td>26.53</td>
                  <td>45.38</td>
                  <td>57.99</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>MMAlaya</td>
                  <td>7.8B</td>
                  <td>32.81</td>
                  <td>32.02</td>
                  <td>29.33</td>
                  <td>30.22</td>
                  <td>35.02</td>
                  <td>24.02</td>
                  <td>48.43</td>
                  <td>20.93</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>Yi-VL-6B</td>
                  <td>6.6B</td>
                  <td>33.27</td>
                  <td>34.00</td>
                  <td>31.42</td>
                  <td>32.26</td>
                  <td>37.15</td>
                  <td>24.31</td>
                  <td>50.25</td>
                  <td>44.32</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>LLaVA-NeXT-vicuna-7B</td>
                  <td>7.1B</td>
                  <td>34.59</td>
                  <td>35.59</td>
                  <td>33.06</td>
                  <td>32.95</td>
                  <td>38.96</td>
                  <td>27.06</td>
                  <td>44.75</td>
                  <td>42.45</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>CogVLM-Chat</td>
                  <td>17B</td>
                  <td>35.46</td>
                  <td>35.83</td>
                  <td>34.13</td>
                  <td>34.49</td>
                  <td>38.55</td>
                  <td>25.25</td>
                  <td>47.09</td>
                  <td><b>90.26</b></td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>Qwen-7B</td>
                  <td>9.6B</td>
                  <td>35.58</td>
                  <td>35.55</td>
                  <td>33.20</td>
                  <td>33.43</td>
                  <td>38.95</td>
                  <td>24.49</td>
                  <td>44.95</td>
                  <td>56.97</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>mPLUG-Owl2</td>
                  <td>8.2B</td>
                  <td>36.07</td>
                  <td>35.89</td>
                  <td>33.68</td>
                  <td>34.74</td>
                  <td>38.80</td>
                  <td>24.90</td>
                  <td>42.59</td>
                  <td>41.84</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>Monkey</td>
                  <td>9.8B</td>
                  <td>36.24</td>
                  <td>35.92</td>
                  <td>33.18</td>
                  <td>34.01</td>
                  <td>39.32</td>
                  <td>25.42</td>
                  <td>44.57</td>
                  <td>42.35</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>ShareCaptioner</td>
                  <td>8B</td>
                  <td>36.34</td>
                  <td>36.07</td>
                  <td>34.74</td>
                  <td>35.93</td>
                  <td>38.25</td>
                  <td>24.37</td>
                  <td>40.00</td>
                  <td>16.95</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>Qwen-7B-Chat</td>
                  <td>9.6B</td>
                  <td>36.63</td>
                  <td>36.35</td>
                  <td>34.45</td>
                  <td>35.20</td>
                  <td>39.55</td>
                  <td>22.04</td>
                  <td>42.88</td>
                  <td><u>81.23</u></td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>LLaVA-NeXT-mistral-7B</td>
                  <td>7.6B</td>
                  <td>36.71</td>
                  <td>37.02</td>
                  <td>36.29</td>
                  <td>35.20</td>
                  <td>39.34</td>
                  <td>27.87</td>
                  <td>44.05</td>
                  <td>47.70</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>ShareGPT4V-7B</td>
                  <td>7.2B</td>
                  <td>36.98</td>
                  <td>36.52</td>
                  <td>34.74</td>
                  <td>35.15</td>
                  <td>39.24</td>
                  <td>26.18</td>
                  <td>46.11</td>
                  <td>43.52</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>LLAVA-V1.5-7B-xtuner</td>
                  <td>7.2B</td>
                  <td>37.33</td>
                  <td>37.96</td>
                  <td>36.75</td>
                  <td>36.34</td>
                  <td>40.55</td>
                  <td>27.52</td>
                  <td>46.78</td>
                  <td>43.06</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>Emu2-Chat</td>
                  <td>37B</td>
                  <td>37.44</td>
                  <td>35.54</td>
                  <td>36.54</td>
                  <td>27.62</td>
                  <td>39.57</td>
                  <td>27.76</td>
                  <td>44.29</td>
                  <td>37.65</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>LLAVA-V1.5-7B</td>
                  <td>7.2B</td>
                  <td>37.49</td>
                  <td>37.72</td>
                  <td>36.45</td>
                  <td>36.65</td>
                  <td>40.38</td>
                  <td>25.36</td>
                  <td>14.10</td>
                  <td>57.09</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>TransCore-M</td>
                  <td>13.4B</td>
                  <td>38.10</td>
                  <td>38.43</td>
                  <td>36.09</td>
                  <td>36.06</td>
                  <td>42.04</td>
                  <td>26.53</td>
                  <td>45.34</td>
                  <td>40.93</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>LLAVA-V1.5-13b-xtuner</td>
                  <td>13.4B</td>
                  <td>38.39</td>
                  <td>38.27</td>
                  <td>38.29</td>
                  <td>36.95</td>
                  <td>40.48</td>
                  <td>25.83</td>
                  <td>47.54</td>
                  <td>33.19</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>InternVL-Chat-V1.5</td>
                  <td>25.5B</td>
                  <td>38.80</td>
                  <td>39.32</td>
                  <td>38.61</td>
                  <td>40.48</td>
                  <td>40.45</td>
                  <td>29.27</td>
                  <td>31.51</td>
                  <td>24.72</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>XComposer2</td>
                  <td>7B</td>
                  <td>38.92</td>
                  <td>38.95</td>
                  <td>37.86</td>
                  <td>38.52</td>
                  <td>41.00</td>
                  <td>28.34</td>
                  <td>46.43</td>
                  <td>51.87</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>XComposer2-4KHD</td>
                  <td>7B</td>
                  <td>39.01</td>
                  <td>37.93</td>
                  <td>36.84</td>
                  <td>38.02</td>
                  <td>39.84</td>
                  <td>26.65</td>
                  <td>48.83</td>
                  <td>44.08</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>LLAVA-InternLM-7b</td>
                  <td>7.6B</td>
                  <td>39.13</td>
                  <td>38.84</td>
                  <td>37.57</td>
                  <td>36.65</td>
                  <td>41.84</td>
                  <td>27.46</td>
                  <td>50.02</td>
                  <td>40.21</td>
                </tr>
                <tr style="background-color: rgba(117, 209, 215, 0.1);">
                  <td>InternVL-Chat-V1.1</td>
      <td>19B</td>
      <td>39.18</td>
      <td>38.93</td>
      <td>38.54</td>
      <td>40.00</td>
      <td>40.07</td>
      <td>28.16</td>
      <td>39.82</td>
      <td>27.32</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>OmniLMM-12B</td>
      <td>12B</td>
      <td>39.41</td>
      <td>38.74</td>
      <td>36.70</td>
      <td>36.86</td>
      <td>41.77</td>
      <td>28.57</td>
      <td>46.17</td>
      <td>43.01</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>Monkey-Chat</td>
      <td>9.8B</td>
      <td>39.76</td>
      <td>39.00</td>
      <td>37.16</td>
      <td>37.75</td>
      <td>42.13</td>
      <td>25.36</td>
      <td>43.91</td>
      <td>28.86</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>DeepSeek-VL-1.3B</td>
      <td>1.3B</td>
      <td>39.92</td>
      <td>40.54</td>
      <td>40.61</td>
      <td>40.71</td>
      <td>42.13</td>
      <td>27.64</td>
      <td>48.71</td>
      <td>21.38</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>MiniCPM-V</td>
      <td>2.8B</td>
      <td>40.05</td>
      <td>40.89</td>
      <td>39.48</td>
      <td>39.18</td>
      <td>44.08</td>
      <td>27.00</td>
      <td>42.87</td>
      <td>32.09</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>InternVL-Chat-V1.2</td>
      <td>40B</td>
      <td>40.53</td>
      <td>39.57</td>
      <td>39.04</td>
      <td>39.75</td>
      <td>41.05</td>
      <td>29.62</td>
      <td>41.08</td>
      <td>46.06</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>InternVL-Chat-V1.2-Plus</td>
      <td>40B</td>
      <td>41.49</td>
      <td>40.25</td>
      <td>40.68</td>
      <td>41.50</td>
      <td>40.82</td>
      <td>30.38</td>
      <td>36.50</td>
      <td>37.09</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>MiniCPM-V2</td>
      <td>2.8B</td>
      <td>41.95</td>
      <td>42.13</td>
      <td>41.11</td>
      <td>41.41</td>
      <td>45.03</td>
      <td>25.95</td>
      <td>50.12</td>
      <td>32.62</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>DeepSeek-VL-7B</td>
      <td>7.3B</td>
      <td>42.92</td>
      <td>42.90</td>
      <td>43.87</td>
      <td>43.60</td>
      <td>44.32</td>
      <td>26.59</td>
      <td>44.16</td>
      <td>18.74</td>
    </tr>
    <tr style="background-color: rgba(117, 209, 215, 0.1);">
      <td>LLAVA-InternLM2-7b</td>
      <td>8.1B</td>
      <td><u>48.35</u></td>
      <td><u>49.85</u></td>
      <td>39.30</td>
      <td>39.14</td>
      <td>61.95</td>
      <td>27.76</td>
      <td><b>50.64</b></td>
      <td>48.25</td>
    </tr>
    <tr>
      <td colspan="10" style="text-align: center;">Proprietary VLMs</td>
    </tr>
    <tr style="background-color: rgba(249, 242, 248, 1);">
      <td>Claude3-Opus</td>
      <td>-</td>
      <td>34.03</td>
      <td>32.24</td>
      <td>33.56</td>
      <td>33.36</td>
      <td>32.17</td>
      <td>24.72</td>
      <td>45.31</td>
      <td>38.98</td>
    </tr>
    <tr style="background-color: rgba(249, 242, 248, 1);">
      <td>Qwen-VL-Max</td>
      <td>-</td>
      <td>43.69</td>
      <td>41.70</td>
      <td>44.23</td>
      <td>44.42</td>
      <td>41.09</td>
      <td>29.10</td>
      <td>31.12</td>
      <td>25.88</td>
    </tr>
    <tr style="background-color: rgba(249, 242, 248, 1);">
      <td>Gemini 1.0</td>
      <td>-</td>
      <td>45.12</td>
      <td>44.65</td>
      <td>44.92</td>
      <td>44.96</td>
      <td><u>46.67</u></td>
      <td>27.46</td>
      <td>49.01</td>
      <td>55.09</td>
    </tr>
    <tr style="background-color: rgba(249, 242, 248, 1);">
      <td>GPT-4V</td>
      <td>-</td>
      <td>45.50</td>
      <td>43.61</td>
      <td>47.87</td>
      <td>46.58</td>
      <td>42.24</td>
      <td>30.32</td>
      <td>45.21</td>
      <td>40.59</td>
    </tr>
    <tr style="background-color: rgba(249, 242, 248, 1);">
      <td>Gemini 1.5</td>
      <td>-</td>
      <td>48.18</td>
      <td>48.03</td>
      <td><u>54.75</u></td>
      <td><b>56.59</b></td>
      <td>43.25</td>
      <td><u>34.17</u></td>
      <td>39.22</td>
      <td>39.34</td>
    </tr>
    <tr style="background-color: rgba(249, 242, 248, 1);">
      <td>GPT-4o</td>
      <td>-</td>
      <td><b>55.32</b></td>
      <td><b>53.88</b></td>
      <td><b>57.09</b></td>
      <td><u>56.49</u></td>
      <td><b>53.70</b></td>
      <td><b>36.21</b></td>
      <td><u>50.60</b></td>
      <td>50.90</td>
    </tr>
  </tbody>
</table>
            <p class="test-desc hidden"> Overall results of different models on the MMMU test set. The best-performing model in each category is <b>in-bold</b>, and the second best is <u>underlined</u>. *: results provided by the authors.</p>
        </div>
      </div>
    </div>



<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<script>
function changeButtonText() {
  var button = document.getElementById('toggleButton');
  var table1 = document.getElementById('table1');
  var table2 = document.getElementById('table2');
  var table3 = document.getElementById('table3');

  if (button.innerHTML.includes("Clinical VQA Tasks Results")) {
    button.innerHTML = "<b style='font-size: larger;'>Departments Results</b> (Click to Switch)";
    table1.classList.add('hidden');
    table2.classList.remove('hidden');
    table3.classList.add('hidden');
  } else if (button.innerHTML.includes("Departments Results")) {
    button.innerHTML = "<b style='font-size: larger;'>Perceptual Granularities Results</b> (Click to Switch)";
    table1.classList.add('hidden');
    table2.classList.add('hidden');
    table3.classList.remove('hidden');
  } else {
    button.innerHTML = "<b style='font-size: larger;'>Clinical VQA Tasks Results</b> (Click to Switch)";
    table1.classList.remove('hidden');
    table2.classList.add('hidden');
    table3.classList.add('hidden');
  }
}
  document.addEventListener('DOMContentLoaded', function() {
    var tables = document.querySelectorAll('table');

    tables.forEach(function(table) {
        if (!table) return;

        var initialRows = Array.from(table.rows).slice(1);
        table.addEventListener('click', function(event) {
            var clickedCell = event.target.closest('td, th');
            if (!clickedCell) return;
            var headerRow = clickedCell.parentNode;
            var columnIndex = Array.from(headerRow.cells).indexOf(clickedCell);
            var type = clickedCell.getAttribute('data-type');

            if (headerRow.rowIndex === 0) {
                if (columnIndex === 0) {
                    table.tBodies[0].innerHTML = '';
                    initialRows.forEach(row => table.tBodies[0].appendChild(row.cloneNode(true)));
                }
            }
        });
    });
});

  // function toggleTables () {
  //     var table1 = document.getElementById('table1');
  //     var table2 = document.getElementById('table2');
  //     var table3 = document.getElementById('table3');
  //     table1.classList.toggle('hidden');
  //     table2.classList.toggle('hidden');
  //     table3.classList.toggle('hidden');
      
  //     var desc1 = document.querySelector('p.validation-desc');
  //     var desc2 = document.querySelector('p.test-desc');
  //     desc1.classList.toggle('hidden');
  //     desc2.classList.toggle('hidden');
  // }

  // document.getElementById('toggleButton').addEventListener('click', toggleTables);

  const canvas = document.getElementById('difficulty_level_chart');
  canvas.style.width = '500px';
  canvas.style.height = '120px';
  const ctx = document.getElementById('difficulty_level_chart').getContext('2d');
  const difficulty_level_chart = new Chart(ctx, {
    type: 'bar',
    data: {
      labels: ['Easy', 'Medium', 'Hard', 'Overall'],
      datasets: [{
        label: 'Adept Fuyu-8B',
        data: [28.9, 27, 26.4, 27.4],
        backgroundColor: 'rgba(196, 123, 160, 0.6)',
        borderColor: 'rgba(196, 123, 160, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(196, 123, 160, 1)'
      },
      {
        label: 'Qwen-VL-7B-Chat',
        data: [39.4, 31.9, 27.6, 32.9],
        backgroundColor: 'rgba(245, 123, 113, 0.6)',
        borderColor: 'rgba(245, 123, 113, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(245, 123, 113, 1)'
      },
      {
        label: 'LLaVA-1.5-13B',
        data: [41.3, 32.7, 26.7, 33.6],
        backgroundColor: 'rgba(255, 208, 80, 0.6)',
        borderColor: 'rgba(255, 208, 80, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(255, 208, 80, 1)'
      },
      {
        label: 'InstructBLIP-T5-XXL',
        data: [40.3, 32.3, 29.4, 33.8],
        backgroundColor: 'rgba(110, 194, 134, 0.6)',
        borderColor: 'rgba(110, 194, 134, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(110, 194, 134, 1)'
      },
      {
        label: 'BLIP-2 FLAN-T5-XXL',
        data: [41, 32.7, 28.5, 34],
        backgroundColor: 'rgba(255, 153, 78, 0.6)',
        borderColor: 'rgba(255, 153, 78, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(255, 153, 78, 1)'
      },
      {
        label: 'Yi-VL-34B',
        data: [51.0, 39.9, 34.0, 41.6],
        backgroundColor: 'rgba(42, 149, 235, 0.6)',
        borderColor: 'rgba(42, 149, 235, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(42, 149, 235, 1)'
      },
      {
        label: 'LLaVA-1.6-34B',
        data: [56.1, 43.4, 34.4, 44.7],
        backgroundColor: 'rgba(183, 156, 220, 0.6)',
        borderColor: 'rgba(183, 156, 220, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(183, 156, 220, 1)'
      },
      {
        label: 'InternVL-Chat-V1.2',
        data: [56.2, 44.8, 37.8, 46.2],
        backgroundColor: 'rgba(143, 169, 209, 0.6)',
        borderColor: 'rgba(143, 169, 209, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(143, 169, 209, 1)'
      },
      {
        label: 'VILA1.5',
        data: [58.1, 45.5, 36.8, 46.9],
        backgroundColor: 'rgba(172, 199, 176, 0.6)',
        borderColor: 'rgba(172, 199, 176, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(172, 199, 176, 1)'
      },
      {
        label: 'GPT-4V(ision) (Playground)',
        data: [76.1, 55.6, 31.2, 55.7],
        backgroundColor: 'rgba(117, 209, 215, 0.6)',
        borderColor: 'rgba(117, 209, 215, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(117, 209, 215, 1)'
      }]
    },
    options: {
    scales: {
      y: {
        beginAtZero: true,
        min: 0,
        max: 100,
        ticks: {
          stepSize: 20,
          font: {
            size: 16
          }
        }
      },
      x: {
        ticks: {
          font: {
            size: 16 
          }
        }
      }
    },
    plugins: {
      legend: {
        labels: {
          font: {
            size: 16 
          }
        }
      },
      tooltip: {
        callbacks: {
          label: function(context) {
            return context.dataset.label + ': ' + context.parsed.y;
          }
        }
      }
    },
      onHover: (event, chartElement) => {
        event.native.target.style.cursor = chartElement[0] ? 'pointer' : 'default';
      }
    }
  });

  const canvas_image = document.getElementById('single_vs_multiple_chart');
  canvas_image.style.width = '500px';
  canvas_image.style.height = '120px';
  const svm = document.getElementById('single_vs_multiple_chart').getContext('2d');
  const single_vs_multiple_chart = new Chart(svm, {
    type: 'bar',
    data: {
      labels: ['InternLM-XComposer2-VL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V(ision) (Playground)'],
      datasets: [{
        label: 'Single Image',
        data: [38.6, 42, 45.1, 46.9, 47, 56.1],
        backgroundColor: 'rgba(42, 149, 235, 0.6)', 
        borderColor: 'rgba(42, 149, 235, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(42, 149, 235, 1)'
      },
      {
        label: 'Multiple Image',
        data: [34.5, 36.6, 40, 38.4, 45.9, 51.7],
        backgroundColor: 'rgba(255, 153, 78, 0.6)', 
        borderColor: 'rgba(255, 153, 78, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(255, 153, 78, 1)'
      },
      {
        label: 'Overall',
        data: [38.2, 41.6, 44.7, 46.2, 46.9, 55.7],
        backgroundColor: 'rgba(110, 194, 134, 0.6)',  
        borderColor: 'rgba(110, 194, 134, 1)',
        borderWidth: 1,
        hoverBackgroundColor: 'rgba(110, 194, 134, 1)'
      }]
    },
    options: {
    scales: {
      y: {
        beginAtZero: true,
        min: 0,
        max: 80,
        ticks: {
          stepSize: 20,
          font: {
            size: 16
          }
        }
      },
      x: {
        ticks: {
          font: {
            size: 16 
          }
        }
      }
    },
    plugins: {
      legend: {
        labels: {
          font: {
            size: 16 
          }
        }
      },
      tooltip: {
        callbacks: {
          label: function(context) {
            return context.dataset.label + ': ' + context.parsed.y;
          }
        }
      }
    },
      onHover: (event, chartElement) => {
        event.native.target.style.cursor = chartElement[0] ? 'pointer' : 'default';
      }
    }
  });


  document.addEventListener('DOMContentLoaded', function() {
    // Data for the "Diagrams" chart
    const data_Diagrams = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [27.6, 30.1, 31.8, 30.0, 32.0, 38.5, 40.8, 44.6, 42.8, 46.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };

    // "data_Diagrams" chart
    new Chart(document.getElementById('chart_Diagrams'), {
        type: 'bar',
        data: data_Diagrams,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Tables" chart
    const data_Tables  = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [26.6, 29.0, 29.8, 27.8, 27.8, 33.6, 40.2, 37.8, 39.9, 61.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Tables'), {
        type: 'bar',
        data: data_Tables,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_PlotsAndCharts " chart
    const data_PlotsAndCharts   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [24.8, 31.8, 36.2, 30.4, 35.8, 43.6, 44.9, 44.3, 47.6, 55.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_PlotsAndCharts'), {
        type: 'bar',
        data: data_PlotsAndCharts ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Photographs " chart
    const data_Photographs   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [27.6, 40.5, 41.4, 44.4, 42.0, 51.9, 57.3, 58.4, 60.9, 64.2],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Photographs'), {
        type: 'bar',
        data: data_Photographs ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });
    
    // "data_ChemicalStructures " chart
    const data_ChemicalStructures   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [25.0, 27.2, 27.1, 26.7, 25.5, 30.4, 32.5, 35.6, 38.7, 50.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_ChemicalStructures'), {
        type: 'bar',
        data: data_ChemicalStructures ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Paintings " chart
    const data_Paintings   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [28.7, 57.2, 53.6, 56.3, 52.1, 67.3, 68.9, 73.1, 71.7, 75.9],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Paintings'), {
        type: 'bar',
        data: data_Paintings ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_GeometricShapes " chart
    const data_GeometricShapes   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [21.1, 25.3, 21.4, 25.6, 28.3, 31, 33.9, 35.7, 37.8, 40.2],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_GeometricShapes'), {
        type: 'bar',
        data: data_GeometricShapes ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_SheetMusic " chart
    const data_SheetMusic   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [35.2, 33.4, 34.6, 35.8, 34.9, 37.3, 33.1, 39.4, 37.6, 38.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_SheetMusic'), {
        type: 'bar',
        data: data_SheetMusic ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_MedicalImages " chart
    const data_MedicalImages   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [25.4, 29.8, 31.6, 36.4, 29.8, 47.8, 50.7, 52.6, 51.8, 59.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MedicalImages'), {
        type: 'bar',
        data: data_MedicalImages ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_PathologicalImages " chart
    const data_PathologicalImages   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [26.5, 27.7, 31.2, 35.2, 35.6, 50.2, 57.3, 56.1, 52.6, 63.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_PathologicalImages'), {
        type: 'bar',
        data: data_PathologicalImages ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_MicroscopicImages " chart
    const data_MicroscopicImages   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [27.0, 37.6, 29.2, 36.3, 32.7, 49.1, 54.9, 50.4, 56.6, 58.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MicroscopicImages'), {
        type: 'bar',
        data: data_MicroscopicImages ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_MRIsCTScansXrays " chart
    const data_MRIsCTScansXrays   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [21.7, 36.9, 33.3, 39.4, 29.8, 44.9, 51.5, 48, 48.5, 50.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MRIsCTScansXrays'), {
        type: 'bar',
        data: data_MRIsCTScansXrays ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_SketchesAndDrafts " chart
    const data_SketchesAndDrafts   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [37.0, 32.1, 29.9, 38.0, 33.7, 45.7, 45.7, 48.9, 52.7, 55.4],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_SketchesAndDrafts'), {
        type: 'bar',
        data: data_SketchesAndDrafts ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Maps " chart
    const data_Maps   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [38.2, 36.5, 45.9, 47.6, 43.5, 52.4, 58.2, 58.2, 62.4, 61.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Maps'), {
        type: 'bar',
        data: data_Maps ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_TechnicalBlueprints " chart
    const data_TechnicalBlueprints   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [24.7, 25.9, 28.4, 25.3, 27.8, 30.9, 37.7, 40.1, 36.4, 38.9],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_TechnicalBlueprints'), {
        type: 'bar',
        data: data_TechnicalBlueprints ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_TreesAndGraphs " chart
    const data_TreesAndGraphs   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [30.1, 28.1, 28.8, 28.8, 34.9, 43.2, 33.6, 37, 41.1, 50.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_TreesAndGraphs'), {
        type: 'bar',
        data: data_TreesAndGraphs ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_MathematicalNotations " chart
    const data_MathematicalNotations   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [15.8, 27.1, 22.6, 21.8, 21.1, 30.8, 33.8, 36.8, 34.6, 45.9],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_MathematicalNotations'), {
        type: 'bar',
        data: data_MathematicalNotations ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_ComicsAndCartoons " chart
    const data_ComicsAndCartoons   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [29.0, 51.9, 49.6, 54.2, 51.1, 64.9, 63.4, 71, 74.8, 68.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_ComicsAndCartoons'), {
        type: 'bar',
        data: data_ComicsAndCartoons ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Sculpture " chart
    const data_Sculpture   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [30.8, 46.2, 49.6, 51.3, 53.0, 65.8, 69.2, 76.9, 71.8, 76.1],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Sculpture'), {
        type: 'bar',
        data: data_Sculpture ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Portraits " chart
    const data_Portraits   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [20.9, 52.7, 46.2, 54.9, 47.3, 62.6, 62.6, 67, 70.3, 70.3],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Portraits'), {
        type: 'bar',
        data: data_Portraits ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Screenshots " chart
    const data_Screenshots   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [38.6, 35.7, 38.6, 34.3, 47.1, 52.9, 60, 51.4, 57.1, 65.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Screenshots'), {
        type: 'bar',
        data: data_Screenshots ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Other " chart
    const data_Other   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [28.3, 38.3, 50.0, 51.7, 58.3, 60, 61.7, 60, 68.3, 68.3],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Other'), {
        type: 'bar',
        data: data_Other ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Poster " chart
    const data_Poster   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [38.6, 50.9, 52.6, 61.4, 64.9, 66.7, 68.4, 71.9, 75.4, 80.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Poster'), {
        type: 'bar',
        data: data_Poster ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_IconsAndSymbols " chart
    const data_IconsAndSymbols   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [23.8, 66.7, 57.1, 59.5, 59.5, 73.8, 73.8, 76.2, 81, 78.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_IconsAndSymbols'), {
        type: 'bar',
        data: data_IconsAndSymbols ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_HistoricalTimelines " chart
    const data_HistoricalTimelines   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [30.0, 36.7, 40.0, 43.3, 43.3, 50, 66.7, 63.3, 63.3, 63.3],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_HistoricalTimelines'), {
        type: 'bar',
        data: data_HistoricalTimelines ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_3DRenderings " chart
    const data_3DRenderings   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [33.3, 28.6, 57.1, 38.1, 47.6, 42.9, 42.9, 57.1, 42.9, 47.6],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_3DRenderings'), {
        type: 'bar',
        data: data_3DRenderings ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_DNASequences " chart
    const data_DNASequences   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [20.0, 45.0, 25.0, 25.0, 45.0, 45, 30, 30, 30, 55.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_DNASequences'), {
        type: 'bar',
        data: data_DNASequences ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Landscapes " chart
    const data_Landscapes   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [43.8, 43.8, 50.0, 31.2, 62.5, 50, 68.8, 62.5, 68.8, 68.8],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Landscapes'), {
        type: 'bar',
        data: data_Landscapes ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_LogosAndBranding " chart
    const data_LogosAndBranding   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [21.4, 57.1, 64.3, 35.7, 50.0, 57.1, 78.6, 78.6, 71.4, 85.7],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_LogosAndBranding'), {
        type: 'bar',
        data: data_LogosAndBranding ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,
            max: 100,
            ticks: {
              stepSize: 20
            }
          },
          x: {
            display: false
          }
        },
        plugins: {
          legend: {
            display: false
          },
          tooltip: {
          }
        }
      }
    });

    // "data_Advertisements " chart
    const data_Advertisements   = {
        labels: ['Adept Fuyu-8B', 'Qwen-VL-7B-Chat', 'InstructBLIP-T5-XXL', 'LLaVA-1.5-13B', 'BLIP-2 FLAN-T5-XXL', 'Yi-VL-34B', 'LLaVA-1.6-34B', 'InternVL-Chat-V1.2', 'VILA1.5', 'GPT-4V'],
        datasets: [{
            data: [30.0, 60.0, 50.0, 60.0, 70.0, 80, 70, 80, 80, 100.0],
            backgroundColor: ['rgba(196, 123, 160, 0.6)', 'rgba(245, 123, 113, 0.6)', 'rgba(255, 208, 80, 0.6)', 'rgba(110, 194, 134, 0.6)', 'rgba(255, 153, 78, 0.6)', 'rgba(42, 149, 235, 0.6)','rgba(183, 156, 220, 0.6)' ,'rgba(143, 169, 209, 0.6)' ,'rgba(72, 199, 176, 0.6)' ,'rgba(117, 209, 215, 0.6)'],
            borderColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,0.4)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' ,  'rgba(117, 209, 215, 1)'],
            hoverBackgroundColor: ['rgba(196, 123, 160, 1)', 'rgba(245, 123, 113,1)', 'rgba(255, 208, 80, 1)', 'rgba(110, 194, 134, 1)', 'rgba(255, 153, 78, 1)', 'rgba(42, 149, 235, 1)','rgba(183, 156, 220, 1)' ,'rgba(143, 169, 209, 1)' ,'rgba(72, 199, 176, 1)' , 'rgba(117, 209, 215, 1)']
        }]
    };
    new Chart(document.getElementById('chart_Advertisements'), {
        type: 'bar',
        data: data_Advertisements ,
        options: {
        scales: {
          y: {
            beginAtZero: true,
            min: 0,     
            max: 100,   
            ticks: {
              stepSize: 20 
            }
          },
          x: {
            display: false 
          }
        },
        plugins: {
          legend: {
            display: false 
          },
          tooltip: {
          }
        }
      }
    });
});

</script>
<style>
  .hidden {
      display: none;
  }
  .sortable:hover {
      cursor: pointer;
  }
  .asc::after {
      content: ' ↑';
  }
  .desc::after {
      content: ' ↓';
  }
  #toggleButton {
    background-color: #ffffff;
    border: 1px solid #dddddd;
    color: #555555;
    padding: 10px 20px;
    text-align: center;
    text-decoration: none;
    display: inline-block;
    font-size: 14px;
    margin: 4px 2px;
    cursor: pointer;
    border-radius: 25px; 
    box-shadow: 0 4px 8px 0 rgba(0,0,0,0.2);
    transition-duration: 0.4s;
  }

  #toggleButton:hover {
    box-shadow: 0 12px 16px 0 rgba(0,0,0,0.24), 0 17px 50px 0 rgba(0,0,0,0.19); /* 鼠标悬停时的阴影效果 */
  }

  table {
    border-collapse: collapse;
    width: 100%;
    margin-top: 5px;
    border: 1px solid #ddd;
    font-size: 14px;
  }

  th, td {
      text-align: left;
      padding: 8px;
  }

  th {
      background-color: #f2f2f2;
      border-bottom: 2px solid #ddd;
  }

  td:hover {background-color: #ffffff;}
</style>

    <!-- End of Statcounter Code -->

  </body>
  </html>
